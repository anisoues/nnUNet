{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f719bdb",
   "metadata": {
    "id": "THifmOYu9Cip"
   },
   "source": [
    "# 1) Import des packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3eaab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24208/3352677732.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnnunet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSimpleITK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgraphviz\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphviz'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import nnunet\n",
    "import SimpleITK\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cab40e",
   "metadata": {
    "id": "JAvjVPF0_7t3"
   },
   "source": [
    "# 2) Parametrages des environnements généraux de nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "545901ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "842d5b2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/scratch/aoueslati/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24208/457690647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/scratch/aoueslati/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Environnement principal de travail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfolder_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmount_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"nnUNet_Fine-tuning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmount_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/scratch/aoueslati/'"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/scratch/aoueslati/\") #Environnement principal de travail\n",
    "folder_dir = os.getcwd()\n",
    "mount_dir = os.path.join(folder_dir, \"nnUNet_Fine-tuning\")\n",
    "base_dir=os.getcwd()\n",
    "mount_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "483f008a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24208/1036056766.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbase_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'base_dir' is not defined"
     ]
    }
   ],
   "source": [
    "base_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea12149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_if_dont_exist(folder_path,overwrite=False):      \n",
    "    \"\"\"\n",
    "    creates a folder if it does not exists\n",
    "    input: \n",
    "    folder_path : relative path of the folder which needs to be created\n",
    "    over_write :(default: False) if True overwrite the existing folder \n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        \n",
    "        if not overwrite:\n",
    "            print(f\"{folder_path} exists.\")\n",
    "        else:\n",
    "            print(f\"{folder_path} overwritten\")\n",
    "            shutil.rmtree(folder_path)\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    else:\n",
    "      os.makedirs(folder_path)\n",
    "      print(f\"{folder_path} created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e81f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory /scratch/aoueslati\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/RawData exists.\n",
      "If No Error Occured Continue Forward. =)\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory {}\".format(folder_dir))\n",
    "path_dict = {\n",
    "    \"nnUNet_raw_data_base\" : os.path.join(mount_dir, \"nnUNet_raw_data_base\"), \n",
    "    \"nnUNet_preprocessed\" : os.path.join(mount_dir, \"nnUNet_preprocessed\"), \n",
    "    \"RESULTS_FOLDER\" : os.path.join(mount_dir, \"nnUNet_Results_Folder\"),\n",
    "    \"RAW_DATA_PATH\" : os.path.join(mount_dir, \"RawData\"), \n",
    "    \"Trainings_launcher\" : os.path.join(mount_dir, \"Trainings_launcher\")\n",
    "}\n",
    "\n",
    "# Write paths to environment variables\n",
    "for env_var, path in path_dict.items():\n",
    "  os.environ[env_var] = path \n",
    "\n",
    "# Check whether all environment variables are set correct!\n",
    "for env_var, path in path_dict.items():\n",
    "    if os.getenv(env_var) != path:\n",
    "        print(\"Error:\")\n",
    "        print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
    "        print(\"Should be {}\".format(path))\n",
    "        print(\"Variable is {}\".format(os.getenv(env_var)))\n",
    "    make_if_dont_exist(path, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf852c",
   "metadata": {},
   "source": [
    "# 3) Parametrages des environnements de notre modèle nnUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5f97c",
   "metadata": {},
   "source": [
    "## a) Installation du modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6910c77",
   "metadata": {},
   "source": [
    "Tâche 105 de nnUNet pré-entrainé sur 50 sujets : Segmentation d'IRMs Cérébrales en 9 classes distinctes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73250f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-16 23:30:14--  https://amubox.univ-amu.fr/s/8Wpazd9y52cJXEZ/download/nnunet_105.zip\n",
      "Resolving amubox.univ-amu.fr (amubox.univ-amu.fr)... 139.124.245.127\n",
      "Connecting to amubox.univ-amu.fr (amubox.univ-amu.fr)|139.124.245.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1147990500 (1.1G) [application/zip]\n",
      "Saving to: 'nnunet_105.zip.1'\n",
      "\n",
      "nnunet_105.zip.1    100%[===================>]   1.07G   224MB/s    in 5.5s    \n",
      "\n",
      "2022-06-16 23:30:20 (201 MB/s) - 'nnunet_105.zip.1' saved [1147990500/1147990500]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(mount_dir, \"RawData\"))\n",
    "!wget https://amubox.univ-amu.fr/s/8Wpazd9y52cJXEZ/download/nnunet_105.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "452b3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "Please cite the following paper when using nnUNet:\r\n",
      "\r\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\r\n",
      "\r\n",
      "\r\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_install_pretrained_model_from_zip nnunet_105.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce2ee4",
   "metadata": {},
   "source": [
    "## b) Téléchargements des données pour le fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de31d06",
   "metadata": {},
   "source": [
    "5 sujets munis de leur ground_truth. Tâche identique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dd4c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/imagesTr exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/labelsTr exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/imagesTs exists.\n"
     ]
    }
   ],
   "source": [
    "os.chdir(mount_dir)\n",
    "\n",
    "# Create Folderstructure for the new task!\n",
    "task_name = 'Task105_DHCP_RIB_MASKED' \n",
    "nnunet_raw_data = os.path.join(os.getenv(\"nnUNet_raw_data_base\"), \"nnUNet_raw_data\")\n",
    "task_folder_name = os.path.join(nnunet_raw_data,task_name)\n",
    "train_image_dir = os.path.join(task_folder_name,'imagesTr') \n",
    "train_label_dir = os.path.join(task_folder_name,'labelsTr') \n",
    "test_dir = os.path.join(task_folder_name,'imagesTs')        \n",
    "main_dir = os.path.join(base_dir,'nnUNet/nnunet')\n",
    "\n",
    "# Create Folder Structure for the DHCP_RIB_MASKED Task on the system\n",
    "make_if_dont_exist(task_folder_name)\n",
    "make_if_dont_exist(train_image_dir)\n",
    "make_if_dont_exist(train_label_dir)\n",
    "make_if_dont_exist(test_dir)\n",
    "\n",
    "training_data_name=\"ground_truth\"      \n",
    "test_data_name=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47d6bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-16 23:30:00--  https://amubox.univ-amu.fr/s/ETWiAynGTFeB9xg/download/ground_truth.zip\n",
      "Resolving amubox.univ-amu.fr (amubox.univ-amu.fr)... 139.124.245.127\n",
      "Connecting to amubox.univ-amu.fr (amubox.univ-amu.fr)|139.124.245.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: 'ground_truth.zip.2'\n",
      "\n",
      "ground_truth.zip.2      [   <=>              ]  46.22M   100MB/s    in 0.5s    \n",
      "\n",
      "2022-06-16 23:30:01 (100 MB/s) - 'ground_truth.zip.2' saved [48470194]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(task_folder_name)\n",
    "# download training data\n",
    "!wget https://amubox.univ-amu.fr/s/ETWiAynGTFeB9xg/download/ground_truth.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "081553bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_folder_name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24208/443452479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#unzipping in nnUNet_raw folder the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask_folder_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unzip ground_truth.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task_folder_name' is not defined"
     ]
    }
   ],
   "source": [
    "#unzipping in nnUNet_raw folder the training data\n",
    "os.chdir(task_folder_name)\n",
    "!unzip ground_truth.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd1a95",
   "metadata": {},
   "source": [
    "### Adaptation des données pour nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "11a942d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for copying, savind and renaming\n",
    "def copy_and_rename(old_location,old_file_name,new_location,new_filename,delete_original = False):\n",
    "\n",
    "    shutil.copy(os.path.join(old_location,old_file_name),new_location)\n",
    "    os.rename(os.path.join(new_location,old_file_name),os.path.join(new_location,new_filename))\n",
    "    if delete_original:\n",
    "        os.remove(os.path.join(old_location,old_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "022609f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "Error",
     "evalue": "Destination path '/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/labelsTr/sub-0665_ses-0791_haste_t2_masked.nii.gz' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mError\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.nii.gz\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;66;03m# putting mask\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m         \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_data_folder_name2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_label_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;66;03m# making 4 copies\u001b[39;00m\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,mask_count2\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m/scratch/aoueslati/anaconda3/lib/python3.9/shutil.py:821\u001b[0m, in \u001b[0;36mmove\u001b[0;34m(src, dst, copy_function)\u001b[0m\n\u001b[1;32m    818\u001b[0m     real_dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, _basename(src))\n\u001b[1;32m    820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(real_dst):\n\u001b[0;32m--> 821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDestination path \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m real_dst)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    823\u001b[0m     os\u001b[38;5;241m.\u001b[39mrename(src, real_dst)\n",
      "\u001b[0;31mError\u001b[0m: Destination path '/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/labelsTr/sub-0665_ses-0791_haste_t2_masked.nii.gz' already exists"
     ]
    }
   ],
   "source": [
    "# putting training images into folder\n",
    "\n",
    "mask_count1 = 1 # change if more mask is available\n",
    "base_data_folder_name1 = os.path.join(task_folder_name, 'ground_truth/t2')\n",
    "\n",
    "for file in os.listdir(base_data_folder_name1):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name1,file),train_image_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count1+1):\n",
    "                new_filename1 = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count1:\n",
    "                    copy_and_rename(base_data_folder_name1,file,train_image_dir,new_filename1,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name1,file,train_image_dir,new_filename1)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name1,file))\n",
    "\n",
    "\n",
    "\n",
    "mask_count2 = 1 # change if more mask is available\n",
    "base_data_folder_name2 = os.path.join(task_folder_name, 'ground_truth/manual_seg')\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(base_data_folder_name2):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name2,file),train_label_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count2+1):\n",
    "                new_filename2 = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count2:\n",
    "                    copy_and_rename(base_data_folder_name2,file,train_label_dir,new_filename2,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name2,file,train_label_dir,new_filename2)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name2,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d64213a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality present: sub-0457_ses-0549_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0483_ses-0589_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0307_ses-0369_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0665_ses-0791_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0427_ses-0517_haste_t2_masked_0000.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def check_modality(filename):\n",
    "    \"\"\"\n",
    "    check for the existence of modality\n",
    "    return False if modality is not found else True\n",
    "    \"\"\"\n",
    "    end = filename.find('.nii.gz')\n",
    "    modality = filename[end-4:end]\n",
    "    for mod in modality: \n",
    "        if not(ord(mod)>=48 and ord(mod)<=57): #if not in 0 to 9 digits\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def rename_for_single_modality(directory):\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        if check_modality(file)==False:\n",
    "            new_name = file[:file.find('.nii.gz')]+\"_0000.nii.gz\"\n",
    "            os.rename(os.path.join(directory,file),os.path.join(directory,new_name))\n",
    "            print(f\"Renamed to {new_name}\")\n",
    "        else:\n",
    "            print(f\"Modality present: {file}\")\n",
    "\n",
    "rename_for_single_modality(train_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "99285748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image files: 5\n",
      "train label files: 5\n",
      "Matches: 0\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(train_image_dir)\n",
    "label_files = os.listdir(train_label_dir)\n",
    "print(\"train image files:\",len(train_files))\n",
    "print(\"train label files:\",len(label_files))\n",
    "print(\"Matches:\",len(set(train_files).intersection(set(label_files))))\n",
    "\n",
    "#assert len(set(train_files).intersection(set(label_files))) == 5 #should be equal to 160 for SCGM Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0668d",
   "metadata": {},
   "source": [
    "## c) Paramétrage de l'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6b047",
   "metadata": {},
   "source": [
    "### - Choix du nombre de classes des données +  modalités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1d3904e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json already exist!\n",
      "dataset.json overwritten!\n"
     ]
    }
   ],
   "source": [
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['name'] = task_name\n",
    "    json_dict['description'] = \"MRI Segmentation\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = \"INT\"\n",
    "    json_dict['licence'] = \"nnUNET\"\n",
    "    json_dict['release'] = \"0.0\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['modality'] = {\n",
    "        \"0\": \"MRI\"\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"a\",\n",
    "        \"1\": \"b\",\n",
    "        \"2\": \"c\",\n",
    "        \"3\": \"d\",\n",
    "        \"4\": \"e\",\n",
    "        \"5\": \"f\",\n",
    "        \"6\": \"g\",\n",
    "        \"7\": \"h\",\n",
    "        \"8\": \"i\",\n",
    "        \"9\": \"j\"\n",
    "    }\n",
    "    \n",
    "    train_ids = os.listdir(train_label_dir)\n",
    "    test_ids = os.listdir(test_dir)\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "    #no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    #removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
    "\n",
    "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286a414",
   "metadata": {},
   "source": [
    "### - Création d'un nouveau ClassTrainer en vue du Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3a2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(base_dir, \"nnUNet/nnunet/training/network_training/\")) #Environnement principal de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d56b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#    Copyright 2020 Division of Medical Image Computing, German Cancer Research Center (DKFZ), Heidelberg, Germany\n",
    "#\n",
    "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#    you may not use this file except in compliance with the License.\n",
    "#    You may obtain a copy of the License at\n",
    "#\n",
    "#        http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#    Unless required by applicable law or agreed to in writing, software\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#    See the License for the specific language governing permissions and\n",
    "#    limitations under the License.\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from nnunet.training.data_augmentation.data_augmentation_moreDA import get_moreDA_augmentation\n",
    "from nnunet.training.loss_functions.deep_supervision import MultipleOutputLoss2\n",
    "from nnunet.utilities.to_torch import maybe_to_torch, to_cuda\n",
    "from nnunet.network_architecture.generic_UNet import Generic_UNet\n",
    "from nnunet.network_architecture.initialization import InitWeights_He\n",
    "from nnunet.network_architecture.neural_network import SegmentationNetwork\n",
    "from nnunet.training.data_augmentation.default_data_augmentation import default_2D_augmentation_params, \\\n",
    "    get_patch_size, default_3D_augmentation_params\n",
    "from nnunet.training.dataloading.dataset_loading import unpack_dataset\n",
    "from nnunet.training.network_training.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunet.utilities.nd_softmax import softmax_helper\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast\n",
    "from nnunet.training.learning_rate.poly_lr import poly_lr\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "\n",
    "\n",
    "class nnUNetTrainerV6(nnUNetTrainer):\n",
    "    \"\"\"\n",
    "    Info for Fabian: same as internal nnUNetTrainerV2_2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, plans_file, fold, output_folder=None, dataset_directory=None, batch_dice=True, stage=None,\n",
    "                 unpack_data=True, deterministic=True, fp16=False):\n",
    "        super().__init__(plans_file, fold, output_folder, dataset_directory, batch_dice, stage, unpack_data,\n",
    "                         deterministic, fp16)\n",
    "        self.max_num_epochs = 100            #Modification du nombre d'epochs\n",
    "        self.initial_lr = 1e-3               #Modification du learning rate  \n",
    "        self.deep_supervision_scales = None\n",
    "        self.ds_loss_weights = None\n",
    "\n",
    "        self.pin_memory = True\n",
    "\n",
    "    def initialize(self, training=True, force_load_plans=False):\n",
    "        \"\"\"\n",
    "        - replaced get_default_augmentation with get_moreDA_augmentation\n",
    "        - enforce to only run this code once\n",
    "        - loss function wrapper for deep supervision\n",
    "        :param training:\n",
    "        :param force_load_plans:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not self.was_initialized:\n",
    "            maybe_mkdir_p(self.output_folder)\n",
    "\n",
    "            if force_load_plans or (self.plans is None):\n",
    "                self.load_plans_file()\n",
    "\n",
    "            self.process_plans(self.plans)\n",
    "\n",
    "            self.setup_DA_params()\n",
    "\n",
    "            ################# Here we wrap the loss for deep supervision ############\n",
    "            # we need to know the number of outputs of the network\n",
    "            net_numpool = len(self.net_num_pool_op_kernel_sizes)\n",
    "\n",
    "            # we give each output a weight which decreases exponentially (division by 2) as the resolution decreases\n",
    "            # this gives higher resolution outputs more weight in the loss\n",
    "            weights = np.array([1 / (2 ** i) for i in range(net_numpool)])\n",
    "\n",
    "            # we don't use the lowest 2 outputs. Normalize weights so that they sum to 1\n",
    "            mask = np.array([True] + [True if i < net_numpool - 1 else False for i in range(1, net_numpool)])\n",
    "            weights[~mask] = 0\n",
    "            weights = weights / weights.sum()\n",
    "            self.ds_loss_weights = weights\n",
    "            # now wrap the loss\n",
    "            self.loss = MultipleOutputLoss2(self.loss, self.ds_loss_weights)\n",
    "            ################# END ###################\n",
    "\n",
    "            self.folder_with_preprocessed_data = join(self.dataset_directory, self.plans['data_identifier'] +\n",
    "                                                      \"_stage%d\" % self.stage)\n",
    "            if training:\n",
    "                self.dl_tr, self.dl_val = self.get_basic_generators()\n",
    "                if self.unpack_data:\n",
    "                    print(\"unpacking dataset\")\n",
    "                    unpack_dataset(self.folder_with_preprocessed_data)\n",
    "                    print(\"done\")\n",
    "                else:\n",
    "                    print(\n",
    "                        \"INFO: Not unpacking data! Training may be slow due to that. Pray you are not using 2d or you \"\n",
    "                        \"will wait all winter for your model to finish!\")\n",
    "\n",
    "                self.tr_gen, self.val_gen = get_moreDA_augmentation(\n",
    "                    self.dl_tr, self.dl_val,\n",
    "                    self.data_aug_params[\n",
    "                        'patch_size_for_spatialtransform'],\n",
    "                    self.data_aug_params,\n",
    "                    deep_supervision_scales=self.deep_supervision_scales,\n",
    "                    pin_memory=self.pin_memory,\n",
    "                    use_nondetMultiThreadedAugmenter=False\n",
    "                )\n",
    "                self.print_to_log_file(\"TRAINING KEYS:\\n %s\" % (str(self.dataset_tr.keys())),\n",
    "                                       also_print_to_console=False)\n",
    "                self.print_to_log_file(\"VALIDATION KEYS:\\n %s\" % (str(self.dataset_val.keys())),\n",
    "                                       also_print_to_console=False)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            self.initialize_network()\n",
    "            self.initialize_optimizer_and_scheduler()\n",
    "\n",
    "            assert isinstance(self.network, (SegmentationNetwork, nn.DataParallel))\n",
    "        else:\n",
    "            self.print_to_log_file('self.was_initialized is True, not running self.initialize again')\n",
    "        self.was_initialized = True\n",
    "\n",
    "    def initialize_network(self):\n",
    "        \"\"\"\n",
    "        - momentum 0.99\n",
    "        - SGD instead of Adam\n",
    "        - self.lr_scheduler = None because we do poly_lr\n",
    "        - deep supervision = True\n",
    "        - i am sure I forgot something here\n",
    "        Known issue: forgot to set neg_slope=0 in InitWeights_He; should not make a difference though\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.threeD:\n",
    "            conv_op = nn.Conv3d\n",
    "            dropout_op = nn.Dropout3d\n",
    "            norm_op = nn.InstanceNorm3d\n",
    "\n",
    "        else:\n",
    "            conv_op = nn.Conv2d\n",
    "            dropout_op = nn.Dropout2d\n",
    "            norm_op = nn.InstanceNorm2d\n",
    "\n",
    "        norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "        dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "        net_nonlin = nn.LeakyReLU\n",
    "        net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        self.network = Generic_UNet(self.num_input_channels, self.base_num_features, self.num_classes,\n",
    "                                    len(self.net_num_pool_op_kernel_sizes),\n",
    "                                    self.conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                                    dropout_op_kwargs,\n",
    "                                    net_nonlin, net_nonlin_kwargs, True, False, lambda x: x, InitWeights_He(1e-2),\n",
    "                                    self.net_num_pool_op_kernel_sizes, self.net_conv_kernel_sizes, False, True, True)\n",
    "        if torch.cuda.is_available():\n",
    "            self.network.cuda()\n",
    "        self.network.inference_apply_nonlin = softmax_helper\n",
    "\n",
    "    def initialize_optimizer_and_scheduler(self):\n",
    "        assert self.network is not None, \"self.initialize_network must be called first\"\n",
    "        self.optimizer = torch.optim.SGD(self.network.parameters(), self.initial_lr, weight_decay=self.weight_decay,\n",
    "                                         momentum=0.99, nesterov=True)\n",
    "        self.lr_scheduler = None\n",
    "\n",
    "    def run_online_evaluation(self, output, target):\n",
    "        \"\"\"\n",
    "        due to deep supervision the return value and the reference are now lists of tensors. We only need the full\n",
    "        resolution output because this is what we are interested in in the end. The others are ignored\n",
    "        :param output:\n",
    "        :param target:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        target = target[0]\n",
    "        output = output[0]\n",
    "        return super().run_online_evaluation(output, target)\n",
    "\n",
    "    def validate(self, do_mirroring: bool = True, use_sliding_window: bool = True,\n",
    "                 step_size: float = 0.5, save_softmax: bool = True, use_gaussian: bool = True, overwrite: bool = True,\n",
    "                 validation_folder_name: str = 'validation_raw', debug: bool = False, all_in_gpu: bool = False,\n",
    "                 segmentation_export_kwargs: dict = None, run_postprocessing_on_folds: bool = True):\n",
    "        \"\"\"\n",
    "        We need to wrap this because we need to enforce self.network.do_ds = False for prediction\n",
    "        \"\"\"\n",
    "        ds = self.network.do_ds\n",
    "        self.network.do_ds = False\n",
    "        ret = super().validate(do_mirroring=do_mirroring, use_sliding_window=use_sliding_window, step_size=step_size,\n",
    "                               save_softmax=save_softmax, use_gaussian=use_gaussian,\n",
    "                               overwrite=overwrite, validation_folder_name=validation_folder_name, debug=debug,\n",
    "                               all_in_gpu=all_in_gpu, segmentation_export_kwargs=segmentation_export_kwargs,\n",
    "                               run_postprocessing_on_folds=run_postprocessing_on_folds)\n",
    "\n",
    "        self.network.do_ds = ds\n",
    "        return ret\n",
    "\n",
    "    def predict_preprocessed_data_return_seg_and_softmax(self, data: np.ndarray, do_mirroring: bool = True,\n",
    "                                                         mirror_axes: Tuple[int] = None,\n",
    "                                                         use_sliding_window: bool = True, step_size: float = 0.5,\n",
    "                                                         use_gaussian: bool = True, pad_border_mode: str = 'constant',\n",
    "                                                         pad_kwargs: dict = None, all_in_gpu: bool = False,\n",
    "                                                         verbose: bool = True, mixed_precision=True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        We need to wrap this because we need to enforce self.network.do_ds = False for prediction\n",
    "        \"\"\"\n",
    "        ds = self.network.do_ds\n",
    "        self.network.do_ds = False\n",
    "        ret = super().predict_preprocessed_data_return_seg_and_softmax(data,\n",
    "                                                                       do_mirroring=do_mirroring,\n",
    "                                                                       mirror_axes=mirror_axes,\n",
    "                                                                       use_sliding_window=use_sliding_window,\n",
    "                                                                       step_size=step_size, use_gaussian=use_gaussian,\n",
    "                                                                       pad_border_mode=pad_border_mode,\n",
    "                                                                       pad_kwargs=pad_kwargs, all_in_gpu=all_in_gpu,\n",
    "                                                                       verbose=verbose,\n",
    "                                                                       mixed_precision=mixed_precision)\n",
    "        self.network.do_ds = ds\n",
    "        return ret\n",
    "\n",
    "    def run_iteration(self, data_generator, do_backprop=True, run_online_evaluation=False):\n",
    "        \"\"\"\n",
    "        gradient clipping improves training stability\n",
    "        :param data_generator:\n",
    "        :param do_backprop:\n",
    "        :param run_online_evaluation:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_dict = next(data_generator)\n",
    "        data = data_dict['data']\n",
    "        target = data_dict['target']\n",
    "\n",
    "        data = maybe_to_torch(data)\n",
    "        target = maybe_to_torch(target)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = to_cuda(data)\n",
    "            target = to_cuda(target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        if self.fp16:\n",
    "            with autocast():\n",
    "                output = self.network(data)\n",
    "                del data\n",
    "                l = self.loss(output, target)\n",
    "\n",
    "            if do_backprop:\n",
    "                self.amp_grad_scaler.scale(l).backward()\n",
    "                self.amp_grad_scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "                self.amp_grad_scaler.step(self.optimizer)\n",
    "                self.amp_grad_scaler.update()\n",
    "        else:\n",
    "            output = self.network(data)\n",
    "            del data\n",
    "            l = self.loss(output, target)\n",
    "\n",
    "            if do_backprop:\n",
    "                l.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "                self.optimizer.step()\n",
    "\n",
    "        if run_online_evaluation:\n",
    "            self.run_online_evaluation(output, target)\n",
    "\n",
    "        del target\n",
    "\n",
    "        return l.detach().cpu().numpy()\n",
    "\n",
    "    def do_split(self):\n",
    "        \"\"\"\n",
    "        The default split is a 5 fold CV on all available training cases. nnU-Net will create a split (it is seeded,\n",
    "        so always the same) and save it as splits_final.pkl file in the preprocessed data directory.\n",
    "        Sometimes you may want to create your own split for various reasons. For this you will need to create your own\n",
    "        splits_final.pkl file. If this file is present, nnU-Net is going to use it and whatever splits are defined in\n",
    "        it. You can create as many splits in this file as you want. Note that if you define only 4 splits (fold 0-3)\n",
    "        and then set fold=4 when training (that would be the fifth split), nnU-Net will print a warning and proceed to\n",
    "        use a random 80:20 data split.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.fold == \"all\":\n",
    "            # if fold==all then we use all images for training and validation\n",
    "            tr_keys = val_keys = list(self.dataset.keys())\n",
    "        else:\n",
    "            splits_file = join(self.dataset_directory, \"splits_final.pkl\")\n",
    "\n",
    "            # if the split file does not exist we need to create it\n",
    "            if not isfile(splits_file):\n",
    "                self.print_to_log_file(\"Creating new 5-fold cross-validation split...\")\n",
    "                splits = []\n",
    "                all_keys_sorted = np.sort(list(self.dataset.keys()))\n",
    "                kfold = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "                for i, (train_idx, test_idx) in enumerate(kfold.split(all_keys_sorted)):\n",
    "                    train_keys = np.array(all_keys_sorted)[train_idx]\n",
    "                    test_keys = np.array(all_keys_sorted)[test_idx]\n",
    "                    splits.append(OrderedDict())\n",
    "                    splits[-1]['train'] = train_keys\n",
    "                    splits[-1]['val'] = test_keys\n",
    "                save_pickle(splits, splits_file)\n",
    "\n",
    "            else:\n",
    "                self.print_to_log_file(\"Using splits from existing split file:\", splits_file)\n",
    "                splits = load_pickle(splits_file)\n",
    "                self.print_to_log_file(\"The split file contains %d splits.\" % len(splits))\n",
    "\n",
    "            self.print_to_log_file(\"Desired fold for training: %d\" % self.fold)\n",
    "            if self.fold < len(splits):\n",
    "                tr_keys = splits[self.fold]['train']\n",
    "                val_keys = splits[self.fold]['val']\n",
    "                self.print_to_log_file(\"This split has %d training and %d validation cases.\"\n",
    "                                       % (len(tr_keys), len(val_keys)))\n",
    "            else:\n",
    "                self.print_to_log_file(\"INFO: You requested fold %d for training but splits \"\n",
    "                                       \"contain only %d folds. I am now creating a \"\n",
    "                                       \"random (but seeded) 80:20 split!\" % (self.fold, len(splits)))\n",
    "                # if we request a fold that is not in the split file, create a random 80:20 split\n",
    "                rnd = np.random.RandomState(seed=12345 + self.fold)\n",
    "                keys = np.sort(list(self.dataset.keys()))\n",
    "                idx_tr = rnd.choice(len(keys), int(len(keys) * 0.8), replace=False)\n",
    "                idx_val = [i for i in range(len(keys)) if i not in idx_tr]\n",
    "                tr_keys = [keys[i] for i in idx_tr]\n",
    "                val_keys = [keys[i] for i in idx_val]\n",
    "                self.print_to_log_file(\"This random 80:20 split has %d training and %d validation cases.\"\n",
    "                                       % (len(tr_keys), len(val_keys)))\n",
    "\n",
    "        tr_keys.sort()\n",
    "        val_keys.sort()\n",
    "        self.dataset_tr = OrderedDict()\n",
    "        for i in tr_keys:\n",
    "            self.dataset_tr[i] = self.dataset[i]\n",
    "        self.dataset_val = OrderedDict()\n",
    "        for i in val_keys:\n",
    "            self.dataset_val[i] = self.dataset[i]\n",
    "\n",
    "    def setup_DA_params(self):\n",
    "        \"\"\"\n",
    "        - we increase roation angle from [-15, 15] to [-30, 30]\n",
    "        - scale range is now (0.7, 1.4), was (0.85, 1.25)\n",
    "        - we don't do elastic deformation anymore\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.deep_supervision_scales = [[1, 1, 1]] + list(list(i) for i in 1 / np.cumprod(\n",
    "            np.vstack(self.net_num_pool_op_kernel_sizes), axis=0))[:-1]\n",
    "\n",
    "        if self.threeD:\n",
    "            self.data_aug_params = default_3D_augmentation_params\n",
    "            self.data_aug_params['rotation_x'] = (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi)\n",
    "            self.data_aug_params['rotation_y'] = (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi)\n",
    "            self.data_aug_params['rotation_z'] = (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi)\n",
    "            if self.do_dummy_2D_aug:\n",
    "                self.data_aug_params[\"dummy_2D\"] = True\n",
    "                self.print_to_log_file(\"Using dummy2d data augmentation\")\n",
    "                self.data_aug_params[\"elastic_deform_alpha\"] = \\\n",
    "                    default_2D_augmentation_params[\"elastic_deform_alpha\"]\n",
    "                self.data_aug_params[\"elastic_deform_sigma\"] = \\\n",
    "                    default_2D_augmentation_params[\"elastic_deform_sigma\"]\n",
    "                self.data_aug_params[\"rotation_x\"] = default_2D_augmentation_params[\"rotation_x\"]\n",
    "        else:\n",
    "            self.do_dummy_2D_aug = False\n",
    "            if max(self.patch_size) / min(self.patch_size) > 1.5:\n",
    "                default_2D_augmentation_params['rotation_x'] = (-15. / 360 * 2. * np.pi, 15. / 360 * 2. * np.pi)\n",
    "            self.data_aug_params = default_2D_augmentation_params\n",
    "        self.data_aug_params[\"mask_was_used_for_normalization\"] = self.use_mask_for_norm\n",
    "\n",
    "        if self.do_dummy_2D_aug:\n",
    "            self.basic_generator_patch_size = get_patch_size(self.patch_size[1:],\n",
    "                                                             self.data_aug_params['rotation_x'],\n",
    "                                                             self.data_aug_params['rotation_y'],\n",
    "                                                             self.data_aug_params['rotation_z'],\n",
    "                                                             self.data_aug_params['scale_range'])\n",
    "            self.basic_generator_patch_size = np.array([self.patch_size[0]] + list(self.basic_generator_patch_size))\n",
    "        else:\n",
    "            self.basic_generator_patch_size = get_patch_size(self.patch_size, self.data_aug_params['rotation_x'],\n",
    "                                                             self.data_aug_params['rotation_y'],\n",
    "                                                             self.data_aug_params['rotation_z'],\n",
    "                                                             self.data_aug_params['scale_range'])\n",
    "\n",
    "        self.data_aug_params[\"scale_range\"] = (0.7, 1.4)\n",
    "        self.data_aug_params[\"do_elastic\"] = False\n",
    "        self.data_aug_params['selected_seg_channels'] = [0]\n",
    "        self.data_aug_params['patch_size_for_spatialtransform'] = self.patch_size\n",
    "\n",
    "        self.data_aug_params[\"num_cached_per_thread\"] = 2\n",
    "\n",
    "    def maybe_update_lr(self, epoch=None):\n",
    "        \"\"\"\n",
    "        if epoch is not None we overwrite epoch. Else we use epoch = self.epoch + 1\n",
    "        (maybe_update_lr is called in on_epoch_end which is called before epoch is incremented.\n",
    "        herefore we need to do +1 here)\n",
    "        :param epoch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if epoch is None:\n",
    "            ep = self.epoch + 1\n",
    "        else:\n",
    "            ep = epoch\n",
    "        self.optimizer.param_groups[0]['lr'] = poly_lr(ep, self.max_num_epochs, self.initial_lr, 0.9)\n",
    "        self.print_to_log_file(\"lr:\", np.round(self.optimizer.param_groups[0]['lr'], decimals=6))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        overwrite patient-based early stopping. Always run to 1000 epochs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super().on_epoch_end()\n",
    "        continue_training = self.epoch < self.max_num_epochs\n",
    "\n",
    "        # it can rarely happen that the momentum of nnUNetTrainerV2 is too high for some dataset. If at epoch 100 the\n",
    "        # estimated validation Dice is still 0 then we reduce the momentum from 0.99 to 0.95\n",
    "        if self.epoch == 100:\n",
    "            if self.all_val_eval_metrics[-1] == 0:\n",
    "                self.optimizer.param_groups[0][\"momentum\"] = 0.95\n",
    "                self.network.apply(InitWeights_He(1e-2))\n",
    "                self.print_to_log_file(\"At epoch 100, the mean foreground Dice was 0. This can be caused by a too \"\n",
    "                                       \"high momentum. High momentum (0.99) is good for datasets where it works, but \"\n",
    "                                       \"sometimes causes issues such as this one. Momentum has now been reduced to \"\n",
    "                                       \"0.95 and network weights have been reinitialized\")\n",
    "        return continue_training\n",
    "\n",
    "    def run_training(self):\n",
    "        \"\"\"\n",
    "        if we run with -c then we need to set the correct lr for the first epoch, otherwise it will run the first\n",
    "        continued epoch with self.initial_lr\n",
    "        we also need to make sure deep supervision in the network is enabled for training, thus the wrapper\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.maybe_update_lr(self.epoch)  # if we dont overwrite epoch then self.epoch+1 is used which is not what we\n",
    "        # want at the start of the training\n",
    "        ds = self.network.do_ds\n",
    "        self.network.do_ds = True\n",
    "        ret = super().run_training()\n",
    "        self.network.do_ds = ds\n",
    "        return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb5d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile nnUNetTrainerV6.py #export en fichier python au bon endroit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498dcdae",
   "metadata": {},
   "source": [
    "# - Preprocess des données avant entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c4587672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "sub-0665_ses-0791_haste_t2_masked\n",
      "sub-0427_ses-0517_haste_t2_masked\n",
      "sub-0483_ses-0589_haste_t2_masked\n",
      "sub-0307_ses-0369_haste_t2_masked\n",
      "sub-0457_ses-0549_haste_t2_masked\n",
      "\n",
      "\n",
      "\n",
      " Task105_DHCP_RIB_MASKED\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [160. 196. 174.]\n",
      "the max shape in the dataset is  [174. 214. 179.]\n",
      "the min shape in the dataset is  [155. 185. 159.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [160. 196. 174.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([160, 196, 174]), 'current_spacing': array([0.5, 0.5, 0.5]), 'original_spacing': array([0.5, 0.5, 0.5]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_cropped_data/Task105_DHCP_RIB_MASKED\n",
      "output_folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 185, 159)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 185, 159)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 191, 167)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 191, 167)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 160, 196, 174)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 160, 196, 174)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 172, 204, 177)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 172, 204, 177)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 174, 214, 179)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 174, 214, 179)} \n",
      "\n",
      "1 10000\n",
      "1 10000\n",
      "2 10000\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "2 10000\n",
      "3 10000\n",
      "1 10000\n",
      "1 10195\n",
      "4 10000\n",
      "4 10000\n",
      "5 10000\n",
      "3 10000\n",
      "5 10000\n",
      "6 10000\n",
      "2 10000\n",
      "2 10000\n",
      "6 10000\n",
      "4 10000\n",
      "7 10000\n",
      "7 10000\n",
      "8 10000\n",
      "5 10000\n",
      "8 10000\n",
      "9 8779\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0665_ses-0791_haste_t2_masked.npz\n",
      "3 10000\n",
      "6 10000\n",
      "3 10000\n",
      "9 9038\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0307_ses-0369_haste_t2_masked.npz\n",
      "7 10000\n",
      "4 10000\n",
      "8 10000\n",
      "4 10000\n",
      "5 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0483_ses-0589_haste_t2_masked.npz\n",
      "5 10000\n",
      "6 10000\n",
      "6 10000\n",
      "7 10000\n",
      "7 10000\n",
      "8 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0457_ses-0549_haste_t2_masked.npz\n",
      "8 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0427_ses-0517_haste_t2_masked.npz\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [160. 196. 174.]\n",
      "the max shape in the dataset is  [174. 214. 179.]\n",
      "the min shape in the dataset is  [155. 185. 159.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [160. 196. 174.]\n",
      "[{'batch_size': 32, 'num_pool_per_axis': [5, 5], 'patch_size': array([224, 192]), 'median_patient_size_in_voxels': array([160, 196, 174]), 'current_spacing': array([0.5, 0.5, 0.5]), 'original_spacing': array([0.5, 0.5, 0.5]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_cropped_data/Task105_DHCP_RIB_MASKED\n",
      "output_folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 185, 159)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 185, 159)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 191, 167)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 191, 167)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 160, 196, 174)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 160, 196, 174)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 172, 204, 177)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 172, 204, 177)} \n",
      "\n",
      "normalization done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 174, 214, 179)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 174, 214, 179)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "1 10000\n",
      "2 10000\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "2 10000\n",
      "1 10000\n",
      "3 10000\n",
      "4 10000\n",
      "1 10195\n",
      "5 10000\n",
      "4 10000\n",
      "3 10000\n",
      "2 10000\n",
      "6 10000\n",
      "5 10000\n",
      "6 10000\n",
      "7 10000\n",
      "4 10000\n",
      "2 10000\n",
      "8 10000\n",
      "7 10000\n",
      "5 10000\n",
      "9 8779\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0665_ses-0791_haste_t2_masked.npz\n",
      "8 10000\n",
      "6 10000\n",
      "3 10000\n",
      "9 9038\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0307_ses-0369_haste_t2_masked.npz\n",
      "3 10000\n",
      "7 10000\n",
      "4 10000\n",
      "8 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0483_ses-0589_haste_t2_masked.npz\n",
      "4 10000\n",
      "5 10000\n",
      "6 10000\n",
      "5 10000\n",
      "7 10000\n",
      "6 10000\n",
      "8 10000\n",
      "7 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0427_ses-0517_haste_t2_masked.npz\n",
      "8 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0457_ses-0549_haste_t2_masked.npz\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 105 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e85dc",
   "metadata": {},
   "source": [
    "# - Lancement d'un entrainement sur le cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21219d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(mount_dir, \"Trainings_launcher\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f26d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!/bin/sh\n",
    "# script Bash pour l'execution d'une tach par slum.\n",
    "## Finetuning\n",
    "#SBATCH -J FineTuning1\n",
    "\n",
    "\n",
    "# Source slurm configuration files\n",
    "# GENERIC CONFIGURATION FOR COMPUTATION ON THE AIX-MARSEILLE MESOCENTRE\n",
    "\n",
    "# Generic configuration\n",
    "#SBATCH --account='b219'  # identifier of the related Mesocentre Project\n",
    "\n",
    "# Mailing configuration\n",
    "#SBATCH --mail-type=ALL  # Mail notification of the events concerning the job : start$\n",
    "#SBATCH --mail-user=oueslati.anis@live.fr\n",
    "\n",
    "\n",
    "# Deep Learning configuration\n",
    "#SBATCH --partition=volta  # partition with gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH -c 10\n",
    "#SBATCH --time=96:00:00\n",
    "\n",
    "# Files pattern\n",
    "#SBATCH -e nnunet-%j_3d_full_res.err\n",
    "#SBATCH -o nnunet-%j_3d_full_res.out\n",
    "\n",
    "#for FOLD in 0 1 2 3 4\n",
    "#do\n",
    "#nnUNet_train 3d_fullres nnUNetTrainerV5 Task105_DHCP_RIB_MASKED  $FOLD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c890fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile fine-tuning.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa15d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 7792051\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch fine-tuning.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8345cf",
   "metadata": {},
   "source": [
    "# - Interprétations des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8e908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(20, 8))\n",
    "\n",
    " \n",
    "subplot(2,3,1)\n",
    "Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_0/progress.png')\n",
    "title(r'fold 0')\n",
    "\n",
    "subplot(2,3,2)\n",
    "Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_1/progress.png')\n",
    "title(r'fold 1')\n",
    "\n",
    "subplot(2,3,3)\n",
    "Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_2/progress.png')\n",
    "title(r'fold 2')\n",
    "\n",
    "subplot(2,3,4)\n",
    "Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_3/progress.png')\n",
    "title(r'fold 3')\n",
    "\n",
    "subplot(2,3,5)\n",
    "Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_4/progress.png')\n",
    "title(r'fold 4')\n",
    "\n",
    "show()\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f32102",
   "metadata": {},
   "source": [
    "# A REVOIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7a783ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "using model stored in  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1\n",
      "This model expects 1 input modalities for each image\n",
      "Found 14 unique case ids, here are some examples: ['sub-0276_ses-0328_haste_t2_masked' 'sub-0698_ses-0824_haste_t2_masked'\n",
      " 'sub-0263_ses-0312_haste_t2_masked' 'sub-0019_ses-0022_haste_t2_masked'\n",
      " 'sub-0916_ses-1054_haste_t2_masked' 'sub-0047_ses-0057_haste_t2_masked'\n",
      " 'sub-0167_ses-0197_haste_t2_masked' 'sub-0276_ses-0328_haste_t2_masked'\n",
      " 'sub-0167_ses-0197_haste_t2_masked' 'sub-0019_ses-0022_haste_t2_masked']\n",
      "If they don't look right, make sure to double check your filenames. They must end with _0000.nii.gz etc\n",
      "number of cases: 14\n",
      "number of cases that still need to be predicted: 14\n",
      "emptying cuda cache\n",
      "loading parameters for folds, [0]\n",
      "using the following model files:  ['/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_0/model_final_checkpoint.model']\n",
      "starting preprocessing generator\n",
      "starting prediction...\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0002_ses-0003_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0019_ses-0022_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0030_ses-0039_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0039_ses-0048_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0047_ses-0057_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0112_ses-0130_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 171, 218, 170) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 153, 189, 161) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 140, 164, 142) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 144, 180, 155) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 148, 179, 158) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 176, 208, 169) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 140, 164, 142)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 140, 164, 142)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 144, 180, 155)} \n",
      "after: no resampling necessary\n",
      "no resampling necessary\n",
      " {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 144, 180, 155)} \n",
      "\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 153, 189, 161)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 153, 189, 161)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 148, 179, 158)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 148, 179, 158)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 171, 218, 170)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 171, 218, 170)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 176, 208, 169)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 176, 208, 169)} \n",
      "\n",
      "(1, 140, 164, 142)\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0638_ses-0761_haste_t2_masked.nii.gz\n",
      "(1, 144, 180, 155)\n",
      "using preprocessor GenericPreprocessor\n",
      "(1, 148, 179, 158)\n",
      "(1, 153, 189, 161)\n",
      "(1, 176, 208, 169)\n",
      "(1, 171, 218, 170)\n",
      "preprocessing /scratch/aoueslati/predicted/sub-0279_ses-0332_haste_t2_masked.nii.gz\n",
      "predicting /scratch/aoueslati/predicted/sub-0047_ses-0057_haste_t2_masked.nii.gz\n",
      "using preprocessor GenericPreprocessor\n",
      "/scratch/aoueslati/anaconda3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "debug: mirroring True mirror_axes (0, 1, 2)\n",
      "/scratch/aoueslati/anaconda3/lib/python3.9/site-packages/torch/autocast_mode.py:162: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n",
      "step_size: 0.5\n",
      "do mirror: True\n",
      "data shape: (1, 140, 164, 142)\n",
      "patch size: [128 128 128]\n",
      "steps (x, y, and z): [[0, 12], [0, 36], [0, 14]]\n",
      "number of tiles: 8\n",
      "computing Gaussian\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 159, 196, 170) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "done\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 159, 196, 170)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 159, 196, 170)} \n",
      "\n",
      "(1, 159, 196, 170)\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 142, 171, 143) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 142, 171, 143)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 142, 171, 143)} \n",
      "\n",
      "(1, 142, 171, 143)\n",
      "^C\n",
      "Process ForkPoolWorker-2:\n",
      "Process Process-4:\n",
      "Process ForkPoolWorker-1:\n",
      "Process Process-3:\n",
      "Process Process-8:\n",
      "Process Process-5:\n",
      "Process Process-7:\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_predict  -t 105 -tr nnUNetTrainerV5 -i /scratch/aoueslati/predict -o /scratch/aoueslati/predicted/ -f 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8371e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_find_best_configuration -m 3d_fullres -t 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5785a807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "usage: Used to determine the postprocessing for a trained model. Useful for when the best configuration (2d, 3d_fullres etc) as selected manually.\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help  show this help message and exit\n",
      "  -m M        U-Net model (2d, 3d_lowres, 3d_fullres or 3d_cascade_fullres)\n",
      "  -t T        Task name or id\n",
      "  -tr TR      nnUNetTrainer class. Default: nnUNetTrainerV2, unless\n",
      "              3d_cascade_fullres (then it's nnUNetTrainerV2CascadeFullRes)\n",
      "  -pl PL      Plans name, Default=nnUNetPlansv2.1\n",
      "  -val VAL    Validation folder name. Default: validation_raw\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_determine_postprocessing -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9edd24f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "import numpy as np\n",
    "from nnunet.paths import preprocessing_output_dir\n",
    "join(preprocessing_output_dir, task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "16185ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'Task105_DHCP_RIB_MASKED'\n",
    "plans_fname = join(preprocessing_output_dir, task_name, 'nnUNetPlansv2.1_plans_3D.pkl')\n",
    "plans = load_pickle(plans_fname)\n",
    "plans['plans_per_stage'][0]['batch_size'] = 2\n",
    "plans['plans_per_stage'][0]['median_patient_size_in_voxels'] = np.array([160, 196, 174])\n",
    "plans['plans_per_stage'][0]['current_spacing'] = np.array([0.5, 0.5, 0.5])\n",
    "plans['plans_per_stage'][0]['patch_size'] = np.array([128, 128, 128])\n",
    "plans['plans_per_stage'][0]['num_pool_per_axis'] = [5, 5, 5]\n",
    "plans['plans_per_stage'][0]['do_dummy_2D_data_aug'] = False\n",
    "plans['plans_per_stage'][0]['original_spacing'] = np.array([0.5, 0.5, 0.5])\n",
    "plans['plans_per_stage'][0]['pool_op_kernel_sizes'] = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]\n",
    "plans['plans_per_stage'][0]['conv_kernel_sizes'] = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
    "save_pickle(plans, join(preprocessing_output_dir, task_name, 'NewnnUNetPlansv2.1_plans_3D.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b55c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 #-overwrite_plans NewnnUNetPlansv2.1_plans_3D.pkl -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier NewnnUNetPlansv2.1_plans_3D.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "063d4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 -overwrite_plans nnUNetPlansv2.1_plans_3D.pkl -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88fbb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -m 3d_fullres -t Task105_DHCP_RIB_MASKED -tr nnUNetTrainerV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4a30646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 -overwrite_plans pretrained_weights/new_model.model -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier pretrained_weights/new_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3582c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_train 3d_fullres nnUNetTrainerV2 Task105_DHCP_RIB_MASKED 0 -w pretrained_weights/new_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c54c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -m 3d_fullres -t 105 -tr nnUNetTrainerV2  -val validation_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6c2e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!nano nnunet-7734648_3d_full_res.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1db8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae90d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26729091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a247e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15eb8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e3b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_1/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80334517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_3/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6bbf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_4/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ddd4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C-t 105 -overwrite_plans ExperimentPlanner3D_v21_Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "331d2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_train 3d_fullres nnUNetTrainerV3 Task105_DHCP_RIB_MASKED 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21b59425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -t 105 -m 3d_fullres -pl nnUNetTrainerV3__nnUNetPlansv2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61376ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_predict -i /scratch/aoueslati/predict -o /scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1 -f 0 -t Task105_DHCP_RIB_MASKED -tr nnUNetTrainerV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9fb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
