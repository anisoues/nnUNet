{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f719bdb",
   "metadata": {
    "id": "THifmOYu9Cip"
   },
   "source": [
    "# 1) Import des packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3eaab6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import nnunet\n",
    "import SimpleITK\n",
    "import graphviz\n",
    "\n",
    "from IPython.display import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cab40e",
   "metadata": {
    "id": "JAvjVPF0_7t3"
   },
   "source": [
    "# 2) Parametrages des environnements généraux de nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "842d5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/aoueslati/nnUNet_Fine-tuning'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/scratch/aoueslati/\") #Environnement principal de travail\n",
    "folder_dir = os.getcwd()\n",
    "mount_dir = os.path.join(folder_dir, \"nnUNet_Fine-tuning\")\n",
    "base_dir=os.getcwd()\n",
    "mount_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea12149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_if_dont_exist(folder_path,overwrite=False):      \n",
    "    \"\"\"\n",
    "    creates a folder if it does not exists\n",
    "    input: \n",
    "    folder_path : relative path of the folder which needs to be created\n",
    "    over_write :(default: False) if True overwrite the existing folder \n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        \n",
    "        if not overwrite:\n",
    "            print(f\"{folder_path} exists.\")\n",
    "        else:\n",
    "            print(f\"{folder_path} overwritten\")\n",
    "            shutil.rmtree(folder_path)\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    else:\n",
    "      os.makedirs(folder_path)\n",
    "      print(f\"{folder_path} created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e81f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory /scratch/aoueslati\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/RawData exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/Trainings_launcher exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/to_predict exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/predicted exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/Predict_launcher created!\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory {}\".format(folder_dir))\n",
    "path_dict = {\n",
    "    \"nnUNet_raw_data_base\" : os.path.join(mount_dir, \"nnUNet_raw_data_base\"), \n",
    "    \"nnUNet_preprocessed\" : os.path.join(mount_dir, \"nnUNet_preprocessed\"), \n",
    "    \"RESULTS_FOLDER\" : os.path.join(mount_dir, \"nnUNet_Results_Folder\"),\n",
    "    \"RAW_DATA_PATH\" : os.path.join(mount_dir, \"RawData\"), \n",
    "    \"Trainings_launcher\" : os.path.join(mount_dir, \"Trainings_launcher\"),\n",
    "    \"to_predict\" : os.path.join(mount_dir, \"to_predict\"),\n",
    "    \"predicted\" : os.path.join(mount_dir, \"predicted\"),\n",
    "    \"Predict_launcher\" : os.path.join(mount_dir, \"Predict_launcher\")\n",
    "}\n",
    "\n",
    "# Write paths to environment variables\n",
    "for env_var, path in path_dict.items():\n",
    "  os.environ[env_var] = path \n",
    "\n",
    "# Check whether all environment variables are set correct!\n",
    "for env_var, path in path_dict.items():\n",
    "    if os.getenv(env_var) != path:\n",
    "        print(\"Error:\")\n",
    "        print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
    "        print(\"Should be {}\".format(path))\n",
    "        print(\"Variable is {}\".format(os.getenv(env_var)))\n",
    "    make_if_dont_exist(path, overwrite=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbf852c",
   "metadata": {},
   "source": [
    "# 3) Parametrages des environnements de notre modèle nnUNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5f97c",
   "metadata": {},
   "source": [
    "## a) Installation du modèle pré-entrainé"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6910c77",
   "metadata": {},
   "source": [
    "Tâche 105 de nnUNet pré-entrainé sur 50 sujets : Segmentation d'IRMs Cérébrales en 9 classes distinctes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73250f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-21 16:15:52--  https://amubox.univ-amu.fr/s/8Wpazd9y52cJXEZ/download/nnunet_105.zip\n",
      "Resolving amubox.univ-amu.fr (amubox.univ-amu.fr)... 139.124.245.127\n",
      "Connecting to amubox.univ-amu.fr (amubox.univ-amu.fr)|139.124.245.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1147990500 (1.1G) [application/zip]\n",
      "Saving to: 'nnunet_105.zip'\n",
      "\n",
      "nnunet_105.zip      100%[===================>]   1.07G   202MB/s    in 5.4s    \n",
      "\n",
      "2022-06-21 16:15:57 (203 MB/s) - 'nnunet_105.zip' saved [1147990500/1147990500]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(os.path.join(mount_dir, \"RawData\"))\n",
    "!wget https://amubox.univ-amu.fr/s/8Wpazd9y52cJXEZ/download/nnunet_105.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452b3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "Please cite the following paper when using nnUNet:\r\n",
      "\r\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\r\n",
      "\r\n",
      "\r\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_install_pretrained_model_from_zip nnunet_105.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16511d27",
   "metadata": {},
   "source": [
    "## b) Prédiction sur 14 sujets avant Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38084dda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aoueslati/nnUNet_Fine-tuning/predicted/pre_fine-tuning created!\n"
     ]
    }
   ],
   "source": [
    "make_if_dont_exist('/scratch/aoueslati/nnUNet_Fine-tuning/predicted/pre_fine-tuning', overwrite=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7c55a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scp -r /scratch/apron/data/datasets/MarsFet/derivatives/segmentation/nnunet/t2_fine_tuning /scratch/aoueslati/nnUNet_Fine-tuning/to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "53026bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(mount_dir, \"Predict_launcher\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6562490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing predict_prefine-tuning.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a predict_prefine-tuning.sh\n",
    "#!/bin/sh\n",
    "# script Bash pour l'execution d'une tach par slum.\n",
    "## Finetuning\n",
    "#SBATCH -J FineTuning1\n",
    "\n",
    "\n",
    "# Source slurm configuration files\n",
    "# GENERIC CONFIGURATION FOR COMPUTATION ON THE AIX-MARSEILLE MESOCENTRE\n",
    "\n",
    "# Generic configuration\n",
    "#SBATCH --account='b219'  # identifier of the related Mesocentre Project\n",
    "\n",
    "# Mailing configuration\n",
    "#SBATCH --mail-type=ALL  # Mail notification of the events concerning the job : start$\n",
    "#SBATCH --mail-user=oueslati.anis@live.fr\n",
    "\n",
    "\n",
    "# Deep Learning configuration\n",
    "#SBATCH --partition=volta  # partition with gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH -c 10\n",
    "#SBATCH --time=96:00:00\n",
    "\n",
    "# Files pattern\n",
    "#SBATCH -e nnunet-%j_3d_full_res.err\n",
    "#SBATCH -o nnunet-%j_3d_full_res.out\n",
    "\n",
    "nnUNet_predict -t 105 -tr nnUNetTrainerV2 -i /scratch/aoueslati/nnUNet_Fine-tuning/to_predict/t2_fine_tuning -o /scratch/aoueslati/nnUNet_Fine-tuning/predicted/pre_fine-tuning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "680e1e8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 7794751\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch predict_prefine-tuning.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cce2ee4",
   "metadata": {},
   "source": [
    "## c) Mise en place fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de31d06",
   "metadata": {},
   "source": [
    "5 sujets munis de leur ground_truth. Tâche identique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dd4c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED created!\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/imagesTr created!\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/labelsTr created!\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/imagesTs created!\n"
     ]
    }
   ],
   "source": [
    "os.chdir(mount_dir)\n",
    "\n",
    "# Create Folderstructure for the new task!\n",
    "task_name = 'Task105_DHCP_RIB_MASKED' \n",
    "nnunet_raw_data = os.path.join(os.getenv(\"nnUNet_raw_data_base\"), \"nnUNet_raw_data\")\n",
    "task_folder_name = os.path.join(nnunet_raw_data,task_name)\n",
    "train_image_dir = os.path.join(task_folder_name,'imagesTr') \n",
    "train_label_dir = os.path.join(task_folder_name,'labelsTr') \n",
    "test_dir = os.path.join(task_folder_name,'imagesTs')        \n",
    "main_dir = os.path.join(base_dir,'nnUNet/nnunet')\n",
    "\n",
    "# Create Folder Structure for the DHCP_RIB_MASKED Task on the system\n",
    "make_if_dont_exist(task_folder_name)\n",
    "make_if_dont_exist(train_image_dir)\n",
    "make_if_dont_exist(train_label_dir)\n",
    "make_if_dont_exist(test_dir)\n",
    "\n",
    "training_data_name=\"ground_truth\"      \n",
    "test_data_name=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "47d6bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-21 16:51:12--  https://amubox.univ-amu.fr/s/ETWiAynGTFeB9xg/download/ground_truth.zip\n",
      "Resolving amubox.univ-amu.fr (amubox.univ-amu.fr)... 139.124.245.127\n",
      "Connecting to amubox.univ-amu.fr (amubox.univ-amu.fr)|139.124.245.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: 'ground_truth.zip'\n",
      "\n",
      "ground_truth.zip        [      <=>           ]  46.22M  41.4MB/s    in 1.1s    \n",
      "\n",
      "2022-06-21 16:51:13 (41.4 MB/s) - 'ground_truth.zip' saved [48470194]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(task_folder_name)\n",
    "# download training data\n",
    "!wget https://amubox.univ-amu.fr/s/ETWiAynGTFeB9xg/download/ground_truth.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "081553bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ground_truth.zip\n",
      "   creating: ground_truth/\n",
      "   creating: ground_truth/manual_seg/\n",
      " extracting: ground_truth/manual_seg/sub-0307_ses-0369_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0427_ses-0517_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0457_ses-0549_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0483_ses-0589_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0665_ses-0791_haste_t2_masked.nii.gz  \n",
      "   creating: ground_truth/t2/\n",
      " extracting: ground_truth/t2/sub-0307_ses-0369_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0427_ses-0517_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0457_ses-0549_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0483_ses-0589_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0665_ses-0791_haste_t2_masked.nii.gz  \n"
     ]
    }
   ],
   "source": [
    "#unzipping in nnUNet_raw folder the training data\n",
    "os.chdir(task_folder_name)\n",
    "!unzip ground_truth.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fd1a95",
   "metadata": {},
   "source": [
    "### Adaptation des données pour nnUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11a942d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for copying, savind and renaming\n",
    "def copy_and_rename(old_location,old_file_name,new_location,new_filename,delete_original = False):\n",
    "\n",
    "    shutil.copy(os.path.join(old_location,old_file_name),new_location)\n",
    "    os.rename(os.path.join(new_location,old_file_name),os.path.join(new_location,new_filename))\n",
    "    if delete_original:\n",
    "        os.remove(os.path.join(old_location,old_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "022609f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting training images into folder\n",
    "\n",
    "mask_count1 = 1 # change if more mask is available\n",
    "base_data_folder_name1 = os.path.join(task_folder_name, 'ground_truth/t2')\n",
    "\n",
    "for file in os.listdir(base_data_folder_name1):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name1,file),train_image_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count1+1):\n",
    "                new_filename1 = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count1:\n",
    "                    copy_and_rename(base_data_folder_name1,file,train_image_dir,new_filename1,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name1,file,train_image_dir,new_filename1)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name1,file))\n",
    "\n",
    "\n",
    "\n",
    "mask_count2 = 1 # change if more mask is available\n",
    "base_data_folder_name2 = os.path.join(task_folder_name, 'ground_truth/manual_seg')\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(base_data_folder_name2):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name2,file),train_label_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count2+1):\n",
    "                new_filename2 = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count2:\n",
    "                    copy_and_rename(base_data_folder_name2,file,train_label_dir,new_filename2,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name2,file,train_label_dir,new_filename2)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name2,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d64213a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed to sub-0665_ses-0791_haste_t2_masked_0000.nii.gz\n",
      "Renamed to sub-0483_ses-0589_haste_t2_masked_0000.nii.gz\n",
      "Renamed to sub-0457_ses-0549_haste_t2_masked_0000.nii.gz\n",
      "Renamed to sub-0307_ses-0369_haste_t2_masked_0000.nii.gz\n",
      "Renamed to sub-0427_ses-0517_haste_t2_masked_0000.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def check_modality(filename):\n",
    "    \"\"\"\n",
    "    check for the existence of modality\n",
    "    return False if modality is not found else True\n",
    "    \"\"\"\n",
    "    end = filename.find('.nii.gz')\n",
    "    modality = filename[end-4:end]\n",
    "    for mod in modality: \n",
    "        if not(ord(mod)>=48 and ord(mod)<=57): #if not in 0 to 9 digits\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def rename_for_single_modality(directory):\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        if check_modality(file)==False:\n",
    "            new_name = file[:file.find('.nii.gz')]+\"_0000.nii.gz\"\n",
    "            os.rename(os.path.join(directory,file),os.path.join(directory,new_name))\n",
    "            print(f\"Renamed to {new_name}\")\n",
    "        else:\n",
    "            print(f\"Modality present: {file}\")\n",
    "\n",
    "rename_for_single_modality(train_image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "99285748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image files: 5\n",
      "train label files: 5\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(train_image_dir)\n",
    "label_files = os.listdir(train_label_dir)\n",
    "print(\"train image files:\",len(train_files))\n",
    "print(\"train label files:\",len(label_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0668d",
   "metadata": {},
   "source": [
    "## c) Paramétrage de l'entrainement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d6b047",
   "metadata": {},
   "source": [
    "### - Choix du nombre de classes des données +  modalités"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1d3904e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json created!\n"
     ]
    }
   ],
   "source": [
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['name'] = task_name\n",
    "    json_dict['description'] = \"MRI Segmentation\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = \"INT\"\n",
    "    json_dict['licence'] = \"nnUNET\"\n",
    "    json_dict['release'] = \"0.0\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['modality'] = {\n",
    "        \"0\": \"MRI\"\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"a\",\n",
    "        \"1\": \"b\",\n",
    "        \"2\": \"c\",\n",
    "        \"3\": \"d\",\n",
    "        \"4\": \"e\",\n",
    "        \"5\": \"f\",\n",
    "        \"6\": \"g\",\n",
    "        \"7\": \"h\",\n",
    "        \"8\": \"i\",\n",
    "        \"9\": \"j\"\n",
    "    }\n",
    "    \n",
    "    train_ids = os.listdir(train_label_dir)\n",
    "    test_ids = os.listdir(test_dir)\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "    #no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    #removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
    "\n",
    "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a286a414",
   "metadata": {},
   "source": [
    "### - Création d'un nouveau ClassTrainer en vue du Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a3a2240",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(base_dir, \"nnUNet/nnunet/training/network_training/\")) #Environnement principal de travail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d56b7b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing nnUNetTrainerV3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a nnUNetTrainerV3.py \n",
    "#    Copyright 2020 Division of Medical Image Computing, German Cancer Research Center (DKFZ), Heidelberg, Germany\n",
    "#\n",
    "#    Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#    you may not use this file except in compliance with the License.\n",
    "#    You may obtain a copy of the License at\n",
    "#\n",
    "#        http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#    Unless required by applicable law or agreed to in writing, software\n",
    "#    distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#    See the License for the specific language governing permissions and\n",
    "#    limitations under the License.\n",
    "\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from nnunet.training.data_augmentation.data_augmentation_moreDA import get_moreDA_augmentation\n",
    "from nnunet.training.loss_functions.deep_supervision import MultipleOutputLoss2\n",
    "from nnunet.utilities.to_torch import maybe_to_torch, to_cuda\n",
    "from nnunet.network_architecture.generic_UNet import Generic_UNet\n",
    "from nnunet.network_architecture.initialization import InitWeights_He\n",
    "from nnunet.network_architecture.neural_network import SegmentationNetwork\n",
    "from nnunet.training.data_augmentation.default_data_augmentation import default_2D_augmentation_params, \\\n",
    "    get_patch_size, default_3D_augmentation_params\n",
    "from nnunet.training.dataloading.dataset_loading import unpack_dataset\n",
    "from nnunet.training.network_training.nnUNetTrainer import nnUNetTrainer\n",
    "from nnunet.utilities.nd_softmax import softmax_helper\n",
    "from sklearn.model_selection import KFold\n",
    "from torch import nn\n",
    "from torch.cuda.amp import autocast\n",
    "from nnunet.training.learning_rate.poly_lr import poly_lr\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "\n",
    "\n",
    "class nnUNetTrainerV3(nnUNetTrainer):\n",
    "    \"\"\"\n",
    "    Info for Fabian: same as internal nnUNetTrainerV2_2\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, plans_file, fold, output_folder=None, dataset_directory=None, batch_dice=True, stage=None,\n",
    "                 unpack_data=True, deterministic=True, fp16=False):\n",
    "        super().__init__(plans_file, fold, output_folder, dataset_directory, batch_dice, stage, unpack_data,\n",
    "                         deterministic, fp16)\n",
    "        self.max_num_epochs = 150            #Modification du nombre d'epochs\n",
    "        self.initial_lr = 1e-3               #Modification du learning rate  \n",
    "        self.deep_supervision_scales = None\n",
    "        self.ds_loss_weights = None\n",
    "\n",
    "        self.pin_memory = True\n",
    "\n",
    "    def initialize(self, training=True, force_load_plans=False):\n",
    "        \"\"\"\n",
    "        - replaced get_default_augmentation with get_moreDA_augmentation\n",
    "        - enforce to only run this code once\n",
    "        - loss function wrapper for deep supervision\n",
    "        :param training:\n",
    "        :param force_load_plans:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if not self.was_initialized:\n",
    "            maybe_mkdir_p(self.output_folder)\n",
    "\n",
    "            if force_load_plans or (self.plans is None):\n",
    "                self.load_plans_file()\n",
    "\n",
    "            self.process_plans(self.plans)\n",
    "\n",
    "            self.setup_DA_params()\n",
    "\n",
    "            ################# Here we wrap the loss for deep supervision ############\n",
    "            # we need to know the number of outputs of the network\n",
    "            net_numpool = len(self.net_num_pool_op_kernel_sizes)\n",
    "\n",
    "            # we give each output a weight which decreases exponentially (division by 2) as the resolution decreases\n",
    "            # this gives higher resolution outputs more weight in the loss\n",
    "            weights = np.array([1 / (2 ** i) for i in range(net_numpool)])\n",
    "\n",
    "            # we don't use the lowest 2 outputs. Normalize weights so that they sum to 1\n",
    "            mask = np.array([True] + [True if i < net_numpool - 1 else False for i in range(1, net_numpool)])\n",
    "            weights[~mask] = 0\n",
    "            weights = weights / weights.sum()\n",
    "            self.ds_loss_weights = weights\n",
    "            # now wrap the loss\n",
    "            self.loss = MultipleOutputLoss2(self.loss, self.ds_loss_weights)\n",
    "            ################# END ###################\n",
    "\n",
    "            self.folder_with_preprocessed_data = join(self.dataset_directory, self.plans['data_identifier'] +\n",
    "                                                      \"_stage%d\" % self.stage)\n",
    "            if training:\n",
    "                self.dl_tr, self.dl_val = self.get_basic_generators()\n",
    "                if self.unpack_data:\n",
    "                    print(\"unpacking dataset\")\n",
    "                    unpack_dataset(self.folder_with_preprocessed_data)\n",
    "                    print(\"done\")\n",
    "                else:\n",
    "                    print(\n",
    "                        \"INFO: Not unpacking data! Training may be slow due to that. Pray you are not using 2d or you \"\n",
    "                        \"will wait all winter for your model to finish!\")\n",
    "\n",
    "                self.tr_gen, self.val_gen = get_moreDA_augmentation(\n",
    "                    self.dl_tr, self.dl_val,\n",
    "                    self.data_aug_params[\n",
    "                        'patch_size_for_spatialtransform'],\n",
    "                    self.data_aug_params,\n",
    "                    deep_supervision_scales=self.deep_supervision_scales,\n",
    "                    pin_memory=self.pin_memory,\n",
    "                    use_nondetMultiThreadedAugmenter=False\n",
    "                )\n",
    "                self.print_to_log_file(\"TRAINING KEYS:\\n %s\" % (str(self.dataset_tr.keys())),\n",
    "                                       also_print_to_console=False)\n",
    "                self.print_to_log_file(\"VALIDATION KEYS:\\n %s\" % (str(self.dataset_val.keys())),\n",
    "                                       also_print_to_console=False)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            self.initialize_network()\n",
    "            self.initialize_optimizer_and_scheduler()\n",
    "\n",
    "            assert isinstance(self.network, (SegmentationNetwork, nn.DataParallel))\n",
    "        else:\n",
    "            self.print_to_log_file('self.was_initialized is True, not running self.initialize again')\n",
    "        self.was_initialized = True\n",
    "\n",
    "    def initialize_network(self):\n",
    "        \"\"\"\n",
    "        - momentum 0.99\n",
    "        - SGD instead of Adam\n",
    "        - self.lr_scheduler = None because we do poly_lr\n",
    "        - deep supervision = True\n",
    "        - i am sure I forgot something here\n",
    "        Known issue: forgot to set neg_slope=0 in InitWeights_He; should not make a difference though\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.threeD:\n",
    "            conv_op = nn.Conv3d\n",
    "            dropout_op = nn.Dropout3d\n",
    "            norm_op = nn.InstanceNorm3d\n",
    "\n",
    "        else:\n",
    "            conv_op = nn.Conv2d\n",
    "            dropout_op = nn.Dropout2d\n",
    "            norm_op = nn.InstanceNorm2d\n",
    "\n",
    "        norm_op_kwargs = {'eps': 1e-5, 'affine': True}\n",
    "        dropout_op_kwargs = {'p': 0, 'inplace': True}\n",
    "        net_nonlin = nn.LeakyReLU\n",
    "        net_nonlin_kwargs = {'negative_slope': 1e-2, 'inplace': True}\n",
    "        self.network = Generic_UNet(self.num_input_channels, self.base_num_features, self.num_classes,\n",
    "                                    len(self.net_num_pool_op_kernel_sizes),\n",
    "                                    self.conv_per_stage, 2, conv_op, norm_op, norm_op_kwargs, dropout_op,\n",
    "                                    dropout_op_kwargs,\n",
    "                                    net_nonlin, net_nonlin_kwargs, True, False, lambda x: x, InitWeights_He(1e-2),\n",
    "                                    self.net_num_pool_op_kernel_sizes, self.net_conv_kernel_sizes, False, True, True)\n",
    "        if torch.cuda.is_available():\n",
    "            self.network.cuda()\n",
    "        self.network.inference_apply_nonlin = softmax_helper\n",
    "\n",
    "    def initialize_optimizer_and_scheduler(self):\n",
    "        assert self.network is not None, \"self.initialize_network must be called first\"\n",
    "        self.optimizer = torch.optim.SGD(self.network.parameters(), self.initial_lr, weight_decay=self.weight_decay,\n",
    "                                         momentum=0.99, nesterov=True)\n",
    "        self.lr_scheduler = None\n",
    "\n",
    "    def run_online_evaluation(self, output, target):\n",
    "        \"\"\"\n",
    "        due to deep supervision the return value and the reference are now lists of tensors. We only need the full\n",
    "        resolution output because this is what we are interested in in the end. The others are ignored\n",
    "        :param output:\n",
    "        :param target:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        target = target[0]\n",
    "        output = output[0]\n",
    "        return super().run_online_evaluation(output, target)\n",
    "\n",
    "    def validate(self, do_mirroring: bool = True, use_sliding_window: bool = True,\n",
    "                 step_size: float = 0.5, save_softmax: bool = True, use_gaussian: bool = True, overwrite: bool = True,\n",
    "                 validation_folder_name: str = 'validation_raw', debug: bool = False, all_in_gpu: bool = False,\n",
    "                 segmentation_export_kwargs: dict = None, run_postprocessing_on_folds: bool = True):\n",
    "        \"\"\"\n",
    "        We need to wrap this because we need to enforce self.network.do_ds = False for prediction\n",
    "        \"\"\"\n",
    "        ds = self.network.do_ds\n",
    "        self.network.do_ds = False\n",
    "        ret = super().validate(do_mirroring=do_mirroring, use_sliding_window=use_sliding_window, step_size=step_size,\n",
    "                               save_softmax=save_softmax, use_gaussian=use_gaussian,\n",
    "                               overwrite=overwrite, validation_folder_name=validation_folder_name, debug=debug,\n",
    "                               all_in_gpu=all_in_gpu, segmentation_export_kwargs=segmentation_export_kwargs,\n",
    "                               run_postprocessing_on_folds=run_postprocessing_on_folds)\n",
    "\n",
    "        self.network.do_ds = ds\n",
    "        return ret\n",
    "\n",
    "    def predict_preprocessed_data_return_seg_and_softmax(self, data: np.ndarray, do_mirroring: bool = True,\n",
    "                                                         mirror_axes: Tuple[int] = None,\n",
    "                                                         use_sliding_window: bool = True, step_size: float = 0.5,\n",
    "                                                         use_gaussian: bool = True, pad_border_mode: str = 'constant',\n",
    "                                                         pad_kwargs: dict = None, all_in_gpu: bool = False,\n",
    "                                                         verbose: bool = True, mixed_precision=True) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        We need to wrap this because we need to enforce self.network.do_ds = False for prediction\n",
    "        \"\"\"\n",
    "        ds = self.network.do_ds\n",
    "        self.network.do_ds = False\n",
    "        ret = super().predict_preprocessed_data_return_seg_and_softmax(data,\n",
    "                                                                       do_mirroring=do_mirroring,\n",
    "                                                                       mirror_axes=mirror_axes,\n",
    "                                                                       use_sliding_window=use_sliding_window,\n",
    "                                                                       step_size=step_size, use_gaussian=use_gaussian,\n",
    "                                                                       pad_border_mode=pad_border_mode,\n",
    "                                                                       pad_kwargs=pad_kwargs, all_in_gpu=all_in_gpu,\n",
    "                                                                       verbose=verbose,\n",
    "                                                                       mixed_precision=mixed_precision)\n",
    "        self.network.do_ds = ds\n",
    "        return ret\n",
    "\n",
    "    def run_iteration(self, data_generator, do_backprop=True, run_online_evaluation=False):\n",
    "        \"\"\"\n",
    "        gradient clipping improves training stability\n",
    "        :param data_generator:\n",
    "        :param do_backprop:\n",
    "        :param run_online_evaluation:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        data_dict = next(data_generator)\n",
    "        data = data_dict['data']\n",
    "        target = data_dict['target']\n",
    "\n",
    "        data = maybe_to_torch(data)\n",
    "        target = maybe_to_torch(target)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            data = to_cuda(data)\n",
    "            target = to_cuda(target)\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        if self.fp16:\n",
    "            with autocast():\n",
    "                output = self.network(data)\n",
    "                del data\n",
    "                l = self.loss(output, target)\n",
    "\n",
    "            if do_backprop:\n",
    "                self.amp_grad_scaler.scale(l).backward()\n",
    "                self.amp_grad_scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "                self.amp_grad_scaler.step(self.optimizer)\n",
    "                self.amp_grad_scaler.update()\n",
    "        else:\n",
    "            output = self.network(data)\n",
    "            del data\n",
    "            l = self.loss(output, target)\n",
    "\n",
    "            if do_backprop:\n",
    "                l.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.network.parameters(), 12)\n",
    "                self.optimizer.step()\n",
    "\n",
    "        if run_online_evaluation:\n",
    "            self.run_online_evaluation(output, target)\n",
    "\n",
    "        del target\n",
    "\n",
    "        return l.detach().cpu().numpy()\n",
    "\n",
    "    def do_split(self):\n",
    "        \"\"\"\n",
    "        The default split is a 5 fold CV on all available training cases. nnU-Net will create a split (it is seeded,\n",
    "        so always the same) and save it as splits_final.pkl file in the preprocessed data directory.\n",
    "        Sometimes you may want to create your own split for various reasons. For this you will need to create your own\n",
    "        splits_final.pkl file. If this file is present, nnU-Net is going to use it and whatever splits are defined in\n",
    "        it. You can create as many splits in this file as you want. Note that if you define only 4 splits (fold 0-3)\n",
    "        and then set fold=4 when training (that would be the fifth split), nnU-Net will print a warning and proceed to\n",
    "        use a random 80:20 data split.\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self.fold == \"all\":\n",
    "            # if fold==all then we use all images for training and validation\n",
    "            tr_keys = val_keys = list(self.dataset.keys())\n",
    "        else:\n",
    "            splits_file = join(self.dataset_directory, \"splits_final.pkl\")\n",
    "\n",
    "            # if the split file does not exist we need to create it\n",
    "            if not isfile(splits_file):\n",
    "                self.print_to_log_file(\"Creating new 5-fold cross-validation split...\")\n",
    "                splits = []\n",
    "                all_keys_sorted = np.sort(list(self.dataset.keys()))\n",
    "                kfold = KFold(n_splits=5, shuffle=True, random_state=12345)\n",
    "                for i, (train_idx, test_idx) in enumerate(kfold.split(all_keys_sorted)):\n",
    "                    train_keys = np.array(all_keys_sorted)[train_idx]\n",
    "                    test_keys = np.array(all_keys_sorted)[test_idx]\n",
    "                    splits.append(OrderedDict())\n",
    "                    splits[-1]['train'] = train_keys\n",
    "                    splits[-1]['val'] = test_keys\n",
    "                save_pickle(splits, splits_file)\n",
    "\n",
    "            else:\n",
    "                self.print_to_log_file(\"Using splits from existing split file:\", splits_file)\n",
    "                splits = load_pickle(splits_file)\n",
    "                self.print_to_log_file(\"The split file contains %d splits.\" % len(splits))\n",
    "\n",
    "            self.print_to_log_file(\"Desired fold for training: %d\" % self.fold)\n",
    "            if self.fold < len(splits):\n",
    "                tr_keys = splits[self.fold]['train']\n",
    "                val_keys = splits[self.fold]['val']\n",
    "                self.print_to_log_file(\"This split has %d training and %d validation cases.\"\n",
    "                                       % (len(tr_keys), len(val_keys)))\n",
    "            else:\n",
    "                self.print_to_log_file(\"INFO: You requested fold %d for training but splits \"\n",
    "                                       \"contain only %d folds. I am now creating a \"\n",
    "                                       \"random (but seeded) 80:20 split!\" % (self.fold, len(splits)))\n",
    "                # if we request a fold that is not in the split file, create a random 80:20 split\n",
    "                rnd = np.random.RandomState(seed=12345 + self.fold)\n",
    "                keys = np.sort(list(self.dataset.keys()))\n",
    "                idx_tr = rnd.choice(len(keys), int(len(keys) * 0.8), replace=False)\n",
    "                idx_val = [i for i in range(len(keys)) if i not in idx_tr]\n",
    "                tr_keys = [keys[i] for i in idx_tr]\n",
    "                val_keys = [keys[i] for i in idx_val]\n",
    "                self.print_to_log_file(\"This random 80:20 split has %d training and %d validation cases.\"\n",
    "                                       % (len(tr_keys), len(val_keys)))\n",
    "\n",
    "        tr_keys.sort()\n",
    "        val_keys.sort()\n",
    "        self.dataset_tr = OrderedDict()\n",
    "        for i in tr_keys:\n",
    "            self.dataset_tr[i] = self.dataset[i]\n",
    "        self.dataset_val = OrderedDict()\n",
    "        for i in val_keys:\n",
    "            self.dataset_val[i] = self.dataset[i]\n",
    "\n",
    "    def setup_DA_params(self):\n",
    "        \"\"\"\n",
    "        - we increase roation angle from [-15, 15] to [-30, 30]\n",
    "        - scale range is now (0.7, 1.4), was (0.85, 1.25)\n",
    "        - we don't do elastic deformation anymore\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        self.deep_supervision_scales = [[1, 1, 1]] + list(list(i) for i in 1 / np.cumprod(\n",
    "            np.vstack(self.net_num_pool_op_kernel_sizes), axis=0))[:-1]\n",
    "\n",
    "        if self.threeD:\n",
    "            self.data_aug_params = default_3D_augmentation_params\n",
    "            self.data_aug_params['rotation_x'] = (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi)\n",
    "            self.data_aug_params['rotation_y'] = (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi)\n",
    "            self.data_aug_params['rotation_z'] = (-30. / 360 * 2. * np.pi, 30. / 360 * 2. * np.pi)\n",
    "            if self.do_dummy_2D_aug:\n",
    "                self.data_aug_params[\"dummy_2D\"] = True\n",
    "                self.print_to_log_file(\"Using dummy2d data augmentation\")\n",
    "                self.data_aug_params[\"elastic_deform_alpha\"] = \\\n",
    "                    default_2D_augmentation_params[\"elastic_deform_alpha\"]\n",
    "                self.data_aug_params[\"elastic_deform_sigma\"] = \\\n",
    "                    default_2D_augmentation_params[\"elastic_deform_sigma\"]\n",
    "                self.data_aug_params[\"rotation_x\"] = default_2D_augmentation_params[\"rotation_x\"]\n",
    "        else:\n",
    "            self.do_dummy_2D_aug = False\n",
    "            if max(self.patch_size) / min(self.patch_size) > 1.5:\n",
    "                default_2D_augmentation_params['rotation_x'] = (-15. / 360 * 2. * np.pi, 15. / 360 * 2. * np.pi)\n",
    "            self.data_aug_params = default_2D_augmentation_params\n",
    "        self.data_aug_params[\"mask_was_used_for_normalization\"] = self.use_mask_for_norm\n",
    "\n",
    "        if self.do_dummy_2D_aug:\n",
    "            self.basic_generator_patch_size = get_patch_size(self.patch_size[1:],\n",
    "                                                             self.data_aug_params['rotation_x'],\n",
    "                                                             self.data_aug_params['rotation_y'],\n",
    "                                                             self.data_aug_params['rotation_z'],\n",
    "                                                             self.data_aug_params['scale_range'])\n",
    "            self.basic_generator_patch_size = np.array([self.patch_size[0]] + list(self.basic_generator_patch_size))\n",
    "        else:\n",
    "            self.basic_generator_patch_size = get_patch_size(self.patch_size, self.data_aug_params['rotation_x'],\n",
    "                                                             self.data_aug_params['rotation_y'],\n",
    "                                                             self.data_aug_params['rotation_z'],\n",
    "                                                             self.data_aug_params['scale_range'])\n",
    "\n",
    "        self.data_aug_params[\"scale_range\"] = (0.7, 1.4)\n",
    "        self.data_aug_params[\"do_elastic\"] = False\n",
    "        self.data_aug_params['selected_seg_channels'] = [0]\n",
    "        self.data_aug_params['patch_size_for_spatialtransform'] = self.patch_size\n",
    "\n",
    "        self.data_aug_params[\"num_cached_per_thread\"] = 2\n",
    "\n",
    "    def maybe_update_lr(self, epoch=None):\n",
    "        \"\"\"\n",
    "        if epoch is not None we overwrite epoch. Else we use epoch = self.epoch + 1\n",
    "        (maybe_update_lr is called in on_epoch_end which is called before epoch is incremented.\n",
    "        herefore we need to do +1 here)\n",
    "        :param epoch:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if epoch is None:\n",
    "            ep = self.epoch + 1\n",
    "        else:\n",
    "            ep = epoch\n",
    "        self.optimizer.param_groups[0]['lr'] = poly_lr(ep, self.max_num_epochs, self.initial_lr, 0.9)\n",
    "        self.print_to_log_file(\"lr:\", np.round(self.optimizer.param_groups[0]['lr'], decimals=6))\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"\n",
    "        overwrite patient-based early stopping. Always run to 1000 epochs\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        super().on_epoch_end()\n",
    "        continue_training = self.epoch < self.max_num_epochs\n",
    "\n",
    "        # it can rarely happen that the momentum of nnUNetTrainerV2 is too high for some dataset. If at epoch 100 the\n",
    "        # estimated validation Dice is still 0 then we reduce the momentum from 0.99 to 0.95\n",
    "        if self.epoch == 100:\n",
    "            if self.all_val_eval_metrics[-1] == 0:\n",
    "                self.optimizer.param_groups[0][\"momentum\"] = 0.95\n",
    "                self.network.apply(InitWeights_He(1e-2))\n",
    "                self.print_to_log_file(\"At epoch 100, the mean foreground Dice was 0. This can be caused by a too \"\n",
    "                                       \"high momentum. High momentum (0.99) is good for datasets where it works, but \"\n",
    "                                       \"sometimes causes issues such as this one. Momentum has now been reduced to \"\n",
    "                                       \"0.95 and network weights have been reinitialized\")\n",
    "        return continue_training\n",
    "\n",
    "    def run_training(self):\n",
    "        \"\"\"\n",
    "        if we run with -c then we need to set the correct lr for the first epoch, otherwise it will run the first\n",
    "        continued epoch with self.initial_lr\n",
    "        we also need to make sure deep supervision in the network is enabled for training, thus the wrapper\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.maybe_update_lr(self.epoch)  # if we dont overwrite epoch then self.epoch+1 is used which is not what we\n",
    "        # want at the start of the training\n",
    "        ds = self.network.do_ds\n",
    "        self.network.do_ds = True\n",
    "        ret = super().run_training()\n",
    "        self.network.do_ds = ds\n",
    "        return ret\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498dcdae",
   "metadata": {},
   "source": [
    "# - Preprocess des données avant entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c4587672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "sub-0665_ses-0791_haste_t2_masked\n",
      "sub-0427_ses-0517_haste_t2_masked\n",
      "sub-0483_ses-0589_haste_t2_masked\n",
      "sub-0307_ses-0369_haste_t2_masked\n",
      "sub-0457_ses-0549_haste_t2_masked\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 155, 191, 167) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 155, 185, 159) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 172, 204, 177) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 174, 214, 179) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "before crop: (1, 248, 302, 216) after crop: (1, 160, 196, 174) spacing: [0.5 0.5 0.5] \n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Task105_DHCP_RIB_MASKED\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [160. 196. 174.]\n",
      "the max shape in the dataset is  [174. 214. 179.]\n",
      "the min shape in the dataset is  [155. 185. 159.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [160. 196. 174.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([160, 196, 174]), 'current_spacing': array([0.5, 0.5, 0.5]), 'original_spacing': array([0.5, 0.5, 0.5]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_cropped_data/Task105_DHCP_RIB_MASKED\n",
      "output_folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 185, 159)} \n",
      "after: before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 191, 167)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 185, 159)} \n",
      "\n",
      " {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 191, 167)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 160, 196, 174)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 160, 196, 174)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 172, 204, 177)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 172, 204, 177)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 174, 214, 179)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 174, 214, 179)} \n",
      "\n",
      "1 10000\n",
      "1 10000\n",
      "1 10000\n",
      "2 10000\n",
      "2 10000\n",
      "2 10000\n",
      "3 10000\n",
      "1 10000\n",
      "3 10000\n",
      "1 10195\n",
      "4 10000\n",
      "4 10000\n",
      "5 10000\n",
      "3 10000\n",
      "2 10000\n",
      "5 10000\n",
      "6 10000\n",
      "2 10000\n",
      "6 10000\n",
      "4 10000\n",
      "7 10000\n",
      "7 10000\n",
      "5 10000\n",
      "8 10000\n",
      "3 10000\n",
      "8 10000\n",
      "9 8779\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0665_ses-0791_haste_t2_masked.npz\n",
      "6 10000\n",
      "3 10000\n",
      "9 9038\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0307_ses-0369_haste_t2_masked.npz\n",
      "7 10000\n",
      "4 10000\n",
      "4 10000\n",
      "8 10000\n",
      "5 10000\n",
      "9 10000\n",
      "5 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0483_ses-0589_haste_t2_masked.npz\n",
      "6 10000\n",
      "6 10000\n",
      "7 10000\n",
      "7 10000\n",
      "8 10000\n",
      "8 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0427_ses-0517_haste_t2_masked.npz\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_stage0/sub-0457_ses-0549_haste_t2_masked.npz\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [160. 196. 174.]\n",
      "the max shape in the dataset is  [174. 214. 179.]\n",
      "the min shape in the dataset is  [155. 185. 159.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [160. 196. 174.]\n",
      "[{'batch_size': 32, 'num_pool_per_axis': [5, 5], 'patch_size': array([224, 192]), 'median_patient_size_in_voxels': array([160, 196, 174]), 'current_spacing': array([0.5, 0.5, 0.5]), 'original_spacing': array([0.5, 0.5, 0.5]), 'pool_op_kernel_sizes': [[2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'do_dummy_2D_data_aug': False}]\n",
      "Initializing to run preprocessing\n",
      "npz folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_cropped_data/Task105_DHCP_RIB_MASKED\n",
      "output_folder: /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 185, 159)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 185, 159)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 155, 191, 167)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 155, 191, 167)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 160, 196, 174)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 160, 196, 174)} \n",
      "\n",
      "normalization...\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "normalization done\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 172, 204, 177)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 172, 204, 177)} \n",
      "\n",
      "no resampling necessary\n",
      "no resampling necessary\n",
      "before: {'spacing': array([0.5, 0.5, 0.5]), 'spacing_transposed': array([0.5, 0.5, 0.5]), 'data.shape (data is transposed)': (1, 174, 214, 179)} \n",
      "after:  {'spacing': array([0.5, 0.5, 0.5]), 'data.shape (data is resampled)': (1, 174, 214, 179)} \n",
      "\n",
      "normalization...\n",
      "normalization...\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "normalization done\n",
      "1 10000\n",
      "1 10000\n",
      "2 10000\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "1 10000\n",
      "2 10000\n",
      "3 10000\n",
      "4 10000\n",
      "1 10195\n",
      "5 10000\n",
      "2 10000\n",
      "4 10000\n",
      "6 10000\n",
      "3 10000\n",
      "5 10000\n",
      "2 10000\n",
      "7 10000\n",
      "6 10000\n",
      "4 10000\n",
      "8 10000\n",
      "7 10000\n",
      "3 10000\n",
      "5 10000\n",
      "9 8779\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0665_ses-0791_haste_t2_masked.npz\n",
      "8 10000\n",
      "3 10000\n",
      "6 10000\n",
      "4 10000\n",
      "9 9038\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0307_ses-0369_haste_t2_masked.npz\n",
      "7 10000\n",
      "5 10000\n",
      "4 10000\n",
      "8 10000\n",
      "6 10000\n",
      "5 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0483_ses-0589_haste_t2_masked.npz\n",
      "7 10000\n",
      "6 10000\n",
      "8 10000\n",
      "7 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0427_ses-0517_haste_t2_masked.npz\n",
      "8 10000\n",
      "9 10000\n",
      "saving:  /scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED/nnUNetData_plans_v2.1_2D_stage0/sub-0457_ses-0549_haste_t2_masked.npz\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 105 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9e85dc",
   "metadata": {},
   "source": [
    "# - Lancement d'un entrainement sur le cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "21219d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(mount_dir, \"Trainings_launcher\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "67f26d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing fine-tuning.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a fine-tuning.sh\n",
    "\n",
    "#!/bin/sh\n",
    "# script Bash pour l'execution d'une tach par slum.\n",
    "## Finetuning\n",
    "#SBATCH -J FineTuning1\n",
    "\n",
    "\n",
    "# Source slurm configuration files\n",
    "# GENERIC CONFIGURATION FOR COMPUTATION ON THE AIX-MARSEILLE MESOCENTRE\n",
    "\n",
    "# Generic configuration\n",
    "#SBATCH --account='b219'  # identifier of the related Mesocentre Project\n",
    "\n",
    "# Mailing configuration\n",
    "#SBATCH --mail-type=ALL  # Mail notification of the events concerning the job : start$\n",
    "#SBATCH --mail-user=oueslati.anis@live.fr\n",
    "\n",
    "\n",
    "# Deep Learning configuration\n",
    "#SBATCH --partition=volta  # partition with gpu\n",
    "#SBATCH --gres=gpu:1\n",
    "#SBATCH -c 10\n",
    "#SBATCH --time=96:00:00\n",
    "\n",
    "# Files pattern\n",
    "#SBATCH -e nnunet-%j_3d_full_res.err\n",
    "#SBATCH -o nnunet-%j_3d_full_res.out\n",
    "\n",
    "for FOLD in 0 1 2 3 4\n",
    "do\n",
    "nnUNet_train 3d_fullres nnUNetTrainerV3 Task105_DHCP_RIB_MASKED  $FOLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa15d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 7792051\r\n"
     ]
    }
   ],
   "source": [
    "!sbatch fine-tuning.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e1f221c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -tr nnUNetTrainerV3 -t 105 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8345cf",
   "metadata": {},
   "source": [
    "# - Interprétations des résultats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6e0e950d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4a83eb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV5__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f32102",
   "metadata": {},
   "source": [
    "# A REVOIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b7a783ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_predict  -t 105 -tr nnUNetTrainerV5 -i /scratch/aoueslati/predict -o /scratch/aoueslati/predicted/ -f 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8371e2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_find_best_configuration -m 3d_fullres -t 105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9edd24f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch\n",
    "#from batchgenerators.utilities.file_and_folder_operations import *\n",
    "#import numpy as np\n",
    "#from nnunet.paths import preprocessing_output_dir\n",
    "#join(preprocessing_output_dir, task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16185ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task_name = 'Task105_DHCP_RIB_MASKED'\n",
    "#plans_fname = join(preprocessing_output_dir, task_name, 'nnUNetPlansv2.1_plans_3D.pkl')\n",
    "#plans = load_pickle(plans_fname)\n",
    "#plans['plans_per_stage'][0]['batch_size'] = 2\n",
    "#plans['plans_per_stage'][0]['median_patient_size_in_voxels'] = np.array([160, 196, 174])\n",
    "#plans['plans_per_stage'][0]['current_spacing'] = np.array([0.5, 0.5, 0.5])\n",
    "#plans['plans_per_stage'][0]['patch_size'] = np.array([128, 128, 128])\n",
    "#plans['plans_per_stage'][0]['num_pool_per_axis'] = [5, 5, 5]\n",
    "#plans['plans_per_stage'][0]['do_dummy_2D_data_aug'] = False\n",
    "#plans['plans_per_stage'][0]['original_spacing'] = np.array([0.5, 0.5, 0.5])\n",
    "#plans['plans_per_stage'][0]['pool_op_kernel_sizes'] = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]\n",
    "#plans['plans_per_stage'][0]['conv_kernel_sizes'] = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
    "#save_pickle(plans, join(preprocessing_output_dir, task_name, 'NewnnUNetPlansv2.1_plans_3D.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6b55c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 #-overwrite_plans NewnnUNetPlansv2.1_plans_3D.pkl -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier NewnnUNetPlansv2.1_plans_3D.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "063d4660",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 -overwrite_plans nnUNetPlansv2.1_plans_3D.pkl -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier Alex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88fbb888",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -m 3d_fullres -t Task105_DHCP_RIB_MASKED -tr nnUNetTrainerV4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4a30646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 -overwrite_plans pretrained_weights/new_model.model -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier pretrained_weights/new_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3582c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_train 3d_fullres nnUNetTrainerV2 Task105_DHCP_RIB_MASKED 0 -w pretrained_weights/new_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c54c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -m 3d_fullres -t 105 -tr nnUNetTrainerV2  -val validation_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6c2e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!nano nnunet-7734648_3d_full_res.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1db8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae90d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26729091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a247e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15eb8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e3b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_1/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80334517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_3/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6bbf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_4/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ddd4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C-t 105 -overwrite_plans ExperimentPlanner3D_v21_Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "331d2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_train 3d_fullres nnUNetTrainerV3 Task105_DHCP_RIB_MASKED 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21b59425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -t 105 -m 3d_fullres -pl nnUNetTrainerV3__nnUNetPlansv2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61376ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_predict -i /scratch/aoueslati/predict -o /scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1 -f 0 -t Task105_DHCP_RIB_MASKED -tr nnUNetTrainerV3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
