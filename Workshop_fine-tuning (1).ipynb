{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f719bdb",
   "metadata": {
    "id": "THifmOYu9Cip"
   },
   "source": [
    "# 1 . Importing Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3eaab6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import basic packages for later use\n",
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "import numpy as np\n",
    "import nnunet\n",
    "import SimpleITK\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842d5b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/aoueslati/nnUNet_Fine-tuning'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_dir = os.getcwd()\n",
    "mount_dir = os.path.join(folder_dir, \"nnUNet_Fine-tuning\")\n",
    "base_dir=os.getcwd()\n",
    "mount_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cab40e",
   "metadata": {
    "id": "JAvjVPF0_7t3"
   },
   "source": [
    "# 2 . Set environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea12149b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_if_dont_exist(folder_path,overwrite=False):\n",
    "    \"\"\"\n",
    "    creates a folder if it does not exists\n",
    "    input: \n",
    "    folder_path : relative path of the folder which needs to be created\n",
    "    over_write :(default: False) if True overwrite the existing folder \n",
    "    \"\"\"\n",
    "    if os.path.exists(folder_path):\n",
    "        \n",
    "        if not overwrite:\n",
    "            print(f\"{folder_path} exists.\")\n",
    "        else:\n",
    "            print(f\"{folder_path} overwritten\")\n",
    "            shutil.rmtree(folder_path)\n",
    "            os.makedirs(folder_path)\n",
    "\n",
    "    else:\n",
    "      os.makedirs(folder_path)\n",
    "      print(f\"{folder_path} created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e81f0a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory /scratch/aoueslati\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_Results_Folder exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/RawData exists.\n",
      "If No Error Occured Continue Forward. =)\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Working Directory {}\".format(folder_dir))\n",
    "path_dict = {\n",
    "    \"nnUNet_raw_data_base\" : os.path.join(mount_dir, \"nnUNet_raw_data_base\"), \n",
    "    \"nnUNet_preprocessed\" : os.path.join(mount_dir, \"nnUNet_preprocessed\"), \n",
    "    \"RESULTS_FOLDER\" : os.path.join(mount_dir, \"nnUNet_Results_Folder\"),\n",
    "    \"RAW_DATA_PATH\" : os.path.join(mount_dir, \"RawData\"), \n",
    "}\n",
    "\n",
    "# Write paths to environment variables\n",
    "for env_var, path in path_dict.items():\n",
    "  os.environ[env_var] = path \n",
    "\n",
    "# Check whether all environment variables are set correct!\n",
    "for env_var, path in path_dict.items():\n",
    "    if os.getenv(env_var) != path:\n",
    "        print(\"Error:\")\n",
    "        print(\"Environment Variable {} is not set correctly!\".format(env_var))\n",
    "        print(\"Should be {}\".format(path))\n",
    "        print(\"Variable is {}\".format(os.getenv(env_var)))\n",
    "    make_if_dont_exist(path, overwrite=False)\n",
    "\n",
    "print(\"If No Error Occured Continue Forward. =)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dd4c057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/imagesTr exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/labelsTr exists.\n",
      "/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_raw_data_base/nnUNet_raw_data/Task105_DHCP_RIB_MASKED/imagesTs exists.\n"
     ]
    }
   ],
   "source": [
    "# Create Folderstructure for the new task!\n",
    "task_name = 'Task105_DHCP_RIB_MASKED' #change here for different task name\n",
    "nnunet_raw_data = os.path.join(os.getenv(\"nnUNet_raw_data_base\"), \"nnUNet_raw_data\")\n",
    "task_folder_name = os.path.join(nnunet_raw_data,task_name)\n",
    "train_image_dir = os.path.join(task_folder_name,'imagesTr')\n",
    "train_label_dir = os.path.join(task_folder_name,'labelsTr')\n",
    "test_dir = os.path.join(task_folder_name,'imagesTs')\n",
    "main_dir = os.path.join(base_dir,'nnUNet/nnunet')\n",
    "\n",
    "# Create Folder Structure for the DHCP_RIB_MASKED Task on the system\n",
    "make_if_dont_exist(task_folder_name)\n",
    "make_if_dont_exist(train_image_dir)\n",
    "make_if_dont_exist(train_label_dir)\n",
    "make_if_dont_exist(test_dir)\n",
    "\n",
    "training_data_name=\"ground_truth\"\n",
    "test_data_name=\"t2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "47d6bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-13 16:13:09--  https://amubox.univ-amu.fr/s/ETWiAynGTFeB9xg/download/ground_truth.zip\n",
      "Resolving amubox.univ-amu.fr (amubox.univ-amu.fr)... 139.124.245.127\n",
      "Connecting to amubox.univ-amu.fr (amubox.univ-amu.fr)|139.124.245.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [application/zip]\n",
      "Saving to: 'ground_truth.zip.1'\n",
      "\n",
      "ground_truth.zip.1      [         <=>        ]  46.22M  14.8MB/s    in 3.1s    \n",
      "\n",
      "2022-06-13 16:13:13 (14.8 MB/s) - 'ground_truth.zip.1' saved [48470194]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(task_folder_name)\n",
    "# download training data\n",
    "!wget https://amubox.univ-amu.fr/s/ETWiAynGTFeB9xg/download/ground_truth.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75ee259d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file exist\n"
     ]
    }
   ],
   "source": [
    "# continue from here again.\n",
    "if os.path.isfile(os.path.join(task_folder_name, training_data_name+'.zip')) is False: \n",
    "  print(\"Please download the dataset zipfiles and place them into the following directory: \\n {}\".format(task_folder_name))\n",
    "else:\n",
    "  print(f'file exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64bc1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json  ground_truth.zip\t  imagesTr  labelsTr\n",
      "ground_truth  ground_truth.zip.1  imagesTs  nnunet_105.zip\n",
      "Training file exists\n",
      "We are currently in working directory /scratch/aoueslati\n"
     ]
    }
   ],
   "source": [
    "# verify that files are in the correct place!\n",
    "os.chdir(task_folder_name)\n",
    "!ls\n",
    "if os.path.isfile(training_data_name+'.zip'):\n",
    "    print(f'Training file exists')\n",
    "else:\n",
    "    print('Training file  is not present in the directory')\n",
    "    print(\"Please check whether {}.zip is in Folder {}\".format(training_data_name, task_folder_name))\n",
    "\n",
    "os.chdir(base_dir)\n",
    "print(\"We are currently in working directory {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "081553bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ground_truth.zip\n",
      "   creating: ground_truth/\n",
      "   creating: ground_truth/manual_seg/\n",
      " extracting: ground_truth/manual_seg/sub-0307_ses-0369_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0427_ses-0517_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0457_ses-0549_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0483_ses-0589_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/manual_seg/sub-0665_ses-0791_haste_t2_masked.nii.gz  \n",
      "   creating: ground_truth/t2/\n",
      " extracting: ground_truth/t2/sub-0307_ses-0369_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0427_ses-0517_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0457_ses-0549_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0483_ses-0589_haste_t2_masked.nii.gz  \n",
      " extracting: ground_truth/t2/sub-0665_ses-0791_haste_t2_masked.nii.gz  \n"
     ]
    }
   ],
   "source": [
    "#unzipping in nnUNet_raw folder the training data\n",
    "os.chdir(task_folder_name)\n",
    "!unzip ground_truth.zip\n",
    "os.chdir(base_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a942d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for copying, savind and renaming\n",
    "def copy_and_rename(old_location,old_file_name,new_location,new_filename,delete_original = False):\n",
    "\n",
    "    shutil.copy(os.path.join(old_location,old_file_name),new_location)\n",
    "    os.rename(os.path.join(new_location,old_file_name),os.path.join(new_location,new_filename))\n",
    "    if delete_original:\n",
    "        os.remove(os.path.join(old_location,old_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "022609f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# putting training images into folder\n",
    "\n",
    "mask_count2 = 1 # change if more mask is available\n",
    "base_data_folder_name2 = os.path.join(task_folder_name, 'ground_truth/manual_seg')\n",
    "\n",
    "\n",
    "\n",
    "for file in os.listdir(base_data_folder_name2):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name2,file),train_label_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count2+1):\n",
    "                new_filename2 = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count2:\n",
    "                    copy_and_rename(base_data_folder_name2,file,train_label_dir,new_filename2,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name2,file,train_label_dir,new_filename2)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name2,file))\n",
    "\n",
    "\n",
    "\n",
    "mask_count1 = 1 # change if more mask is available\n",
    "base_data_folder_name1 = os.path.join(task_folder_name, 'ground_truth/t2')\n",
    "\n",
    "for file in os.listdir(base_data_folder_name1):\n",
    "    # print(file)\n",
    "    if file.endswith('.nii.gz'):\n",
    "        if file.find('mask')!=-1:\n",
    "            # putting mask\n",
    "            shutil.move(os.path.join(base_data_folder_name1,file),train_image_dir)\n",
    "        else:\n",
    "            # making 4 copies\n",
    "            for mask in range(1,mask_count1+1):\n",
    "                new_filename1 = file[:file.find('-image')] + '-mask-r' + str(mask) + '.nii.gz'\n",
    "                if mask==mask_count1:\n",
    "                    copy_and_rename(base_data_folder_name1,file,train_image_dir,new_filename1,delete_original = True)\n",
    "                else:\n",
    "                    copy_and_rename(base_data_folder_name1,file,train_image_dir,new_filename1)\n",
    "    # removing all other files installed due to the unzip\n",
    "    elif file.endswith('.txt'):\n",
    "        os.remove(os.path.join(base_data_folder_name1,file))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d64213a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modality present: sub-0457_ses-0549_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0483_ses-0589_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0307_ses-0369_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0665_ses-0791_haste_t2_masked_0000.nii.gz\n",
      "Modality present: sub-0427_ses-0517_haste_t2_masked_0000.nii.gz\n"
     ]
    }
   ],
   "source": [
    "def check_modality(filename):\n",
    "    \"\"\"\n",
    "    check for the existence of modality\n",
    "    return False if modality is not found else True\n",
    "    \"\"\"\n",
    "    end = filename.find('.nii.gz')\n",
    "    modality = filename[end-4:end]\n",
    "    for mod in modality: \n",
    "        if not(ord(mod)>=48 and ord(mod)<=57): #if not in 0 to 9 digits\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def rename_for_single_modality(directory):\n",
    "    \n",
    "    for file in os.listdir(directory):\n",
    "        \n",
    "        if check_modality(file)==False:\n",
    "            new_name = file[:file.find('.nii.gz')]+\"_0000.nii.gz\"\n",
    "            os.rename(os.path.join(directory,file),os.path.join(directory,new_name))\n",
    "            print(f\"Renamed to {new_name}\")\n",
    "        else:\n",
    "            print(f\"Modality present: {file}\")\n",
    "\n",
    "rename_for_single_modality(train_image_dir)\n",
    "#rename_for_single_modality(train_label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "99285748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train image files: 5\n",
      "train label files: 5\n",
      "Matches: 0\n"
     ]
    }
   ],
   "source": [
    "train_files = os.listdir(train_image_dir)\n",
    "label_files = os.listdir(train_label_dir)\n",
    "print(\"train image files:\",len(train_files))\n",
    "print(\"train label files:\",len(label_files))\n",
    "print(\"Matches:\",len(set(train_files).intersection(set(label_files))))\n",
    "\n",
    "#assert len(set(train_files).intersection(set(label_files))) == 5 #should be equal to 160 for SCGM Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf0668d",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d3904e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset.json already exist!\n",
      "dataset.json overwritten!\n"
     ]
    }
   ],
   "source": [
    "overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
    "json_file_exist = False\n",
    "\n",
    "if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "    print('dataset.json already exist!')\n",
    "    json_file_exist = True\n",
    "\n",
    "if json_file_exist==False or overwrite_json_file:\n",
    "\n",
    "    json_dict = OrderedDict()\n",
    "    json_dict['name'] = task_name\n",
    "    json_dict['description'] = \"MRI Segmentation\"\n",
    "    json_dict['tensorImageSize'] = \"3D\"\n",
    "    json_dict['reference'] = \"INT\"\n",
    "    json_dict['licence'] = \"nnUNET\"\n",
    "    json_dict['release'] = \"0.0\"\n",
    "\n",
    "    #you may mention more than one modality\n",
    "    json_dict['modality'] = {\n",
    "        \"0\": \"MRI\"\n",
    "    }\n",
    "    #labels+1 should be mentioned for all the labels in the dataset\n",
    "    json_dict['labels'] = {\n",
    "        \"0\": \"a\",\n",
    "        \"1\": \"b\",\n",
    "        \"2\": \"c\",\n",
    "        \"3\": \"d\",\n",
    "        \"4\": \"e\",\n",
    "        \"5\": \"f\",\n",
    "        \"6\": \"g\",\n",
    "        \"7\": \"h\",\n",
    "        \"8\": \"i\",\n",
    "        \"9\": \"j\"\n",
    "    }\n",
    "    \n",
    "    train_ids = os.listdir(train_label_dir)\n",
    "    test_ids = os.listdir(test_dir)\n",
    "    json_dict['numTraining'] = len(train_ids)\n",
    "    json_dict['numTest'] = len(test_ids)\n",
    "\n",
    "    #no modality in train image and labels in dataset.json \n",
    "    json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
    "\n",
    "    #removing the modality from test image name to be saved in dataset.json\n",
    "    json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
    "\n",
    "    with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
    "        json.dump(json_dict, f, indent=4, sort_keys=True)\n",
    "\n",
    "    if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
    "        if json_file_exist==False:\n",
    "            print('dataset.json created!')\n",
    "        else: \n",
    "            print('dataset.json overwritten!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86770934",
   "metadata": {},
   "source": [
    "# Import the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73250f47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-06-09 14:49:11--  https://amubox.univ-amu.fr/s/8Wpazd9y52cJXEZ/download/nnunet_105.zip\n",
      "Resolving amubox.univ-amu.fr (amubox.univ-amu.fr)... 139.124.245.127\n",
      "Connecting to amubox.univ-amu.fr (amubox.univ-amu.fr)|139.124.245.127|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1147990500 (1.1G) [application/zip]\n",
      "Saving to: 'nnunet_105.zip'\n",
      "\n",
      "nnunet_105.zip      100%[===================>]   1.07G   203MB/s    in 5.2s    \n",
      "\n",
      "2022-06-09 14:49:17 (209 MB/s) - 'nnunet_105.zip' saved [1147990500/1147990500]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.chdir(base_dir)\n",
    "# download training data\n",
    "!wget https://amubox.univ-amu.fr/s/8Wpazd9y52cJXEZ/download/nnunet_105.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5f97c",
   "metadata": {},
   "source": [
    "# Install the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452b3afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "Please cite the following paper when using nnUNet:\r\n",
      "\r\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\r\n",
      "\r\n",
      "\r\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_install_pretrained_model_from_zip nnunet_105.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498dcdae",
   "metadata": {},
   "source": [
    "# Preprocess "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9edd24f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/scratch/aoueslati/nnUNet_Fine-tuning/nnUNet_preprocessed/Task105_DHCP_RIB_MASKED'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from batchgenerators.utilities.file_and_folder_operations import *\n",
    "import numpy as np\n",
    "from nnunet.paths import preprocessing_output_dir\n",
    "join(preprocessing_output_dir, task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "16185ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'Task105_DHCP_RIB_MASKED'\n",
    "plans_fname = join(preprocessing_output_dir, task_name, 'nnUNetPlansv2.1_plans_3D.pkl')\n",
    "plans = load_pickle(plans_fname)\n",
    "plans['plans_per_stage'][0]['batch_size'] = 2\n",
    "plans['plans_per_stage'][0]['median_patient_size_in_voxels'] = np.array([160, 196, 174])\n",
    "plans['plans_per_stage'][0]['current_spacing'] = np.array([0.5, 0.5, 0.5])\n",
    "plans['plans_per_stage'][0]['patch_size'] = np.array([128, 128, 128])\n",
    "plans['plans_per_stage'][0]['num_pool_per_axis'] = [5, 5, 5]\n",
    "plans['plans_per_stage'][0]['do_dummy_2D_data_aug'] = False\n",
    "plans['plans_per_stage'][0]['original_spacing'] = np.array([0.5, 0.5, 0.5])\n",
    "plans['plans_per_stage'][0]['pool_op_kernel_sizes'] = [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]]\n",
    "plans['plans_per_stage'][0]['conv_kernel_sizes'] = [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]\n",
    "save_pickle(plans, join(preprocessing_output_dir, task_name, 'NewnnUNetPlansv2.1_plans_3D.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4587672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Overwriting plans only works for the 3d planner. I am setting '--planner2d' to None. This will skip 2d planning and preprocessing.\n",
      "sub-0665_ses-0791_haste_t2_masked\n",
      "sub-0427_ses-0517_haste_t2_masked\n",
      "sub-0483_ses-0589_haste_t2_masked\n",
      "sub-0307_ses-0369_haste_t2_masked\n",
      "sub-0457_ses-0549_haste_t2_masked\n",
      "\n",
      "\n",
      "\n",
      " Task105_DHCP_RIB_MASKED\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [160. 196. 174.]\n",
      "the max shape in the dataset is  [174. 214. 179.]\n",
      "the min shape in the dataset is  [155. 185. 159.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [160. 196. 174.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([160, 196, 174]), 'current_spacing': array([0.5, 0.5, 0.5]), 'original_spacing': array([0.5, 0.5, 0.5]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/aoueslati/anaconda3/bin/nnUNet_plan_and_preprocess\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_plan_and_preprocess')())\n",
      "  File \"/scratch/aoueslati/nnUNet/nnunet/experiment_planning/nnUNet_plan_and_preprocess.py\", line 161, in main\n",
      "    exp_planner.run_preprocessing(threads)\n",
      "  File \"/scratch/aoueslati/nnUNet/nnunet/experiment_planning/alternative_experiment_planning/experiment_planner_pretrained.py\", line 41, in run_preprocessing\n",
      "    self.load_pretrained_plans()\n",
      "  File \"/scratch/aoueslati/nnUNet/nnunet/experiment_planning/alternative_experiment_planning/experiment_planner_pretrained.py\", line 31, in load_pretrained_plans\n",
      "    self.plans = load_pickle(self.pretrained_model_plans_file)\n",
      "  File \"/scratch/aoueslati/anaconda3/lib/python3.9/site-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'NewnnUNetPlansv2.1_plans_3D.pkl'\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 105 -overwrite_plans NewnnUNetPlansv2.1_plans_3D.pkl -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier NewnnUNetPlansv2.1_plans_3D.pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "063d4660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Please cite the following paper when using nnUNet:\n",
      "\n",
      "Isensee, F., Jaeger, P.F., Kohl, S.A.A. et al. \"nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation.\" Nat Methods (2020). https://doi.org/10.1038/s41592-020-01008-z\n",
      "\n",
      "\n",
      "If you have questions or suggestions, feel free to open an issue at https://github.com/MIC-DKFZ/nnUNet\n",
      "\n",
      "Overwriting plans only works for the 3d planner. I am setting '--planner2d' to None. This will skip 2d planning and preprocessing.\n",
      "sub-0665_ses-0791_haste_t2_masked\n",
      "sub-0427_ses-0517_haste_t2_masked\n",
      "sub-0483_ses-0589_haste_t2_masked\n",
      "sub-0307_ses-0369_haste_t2_masked\n",
      "sub-0457_ses-0549_haste_t2_masked\n",
      "\n",
      "\n",
      "\n",
      " Task105_DHCP_RIB_MASKED\n",
      "number of threads:  (8, 8) \n",
      "\n",
      "using nonzero mask for normalization\n",
      "Are we using the nonzero mask for normalization? OrderedDict([(0, True)])\n",
      "the median shape of the dataset is  [160. 196. 174.]\n",
      "the max shape in the dataset is  [174. 214. 179.]\n",
      "the min shape in the dataset is  [155. 185. 159.]\n",
      "we don't want feature maps smaller than  4  in the bottleneck\n",
      "the transposed median shape of the dataset is  [160. 196. 174.]\n",
      "generating configuration for 3d_fullres\n",
      "{0: {'batch_size': 2, 'num_pool_per_axis': [5, 5, 5], 'patch_size': array([128, 128, 128]), 'median_patient_size_in_voxels': array([160, 196, 174]), 'current_spacing': array([0.5, 0.5, 0.5]), 'original_spacing': array([0.5, 0.5, 0.5]), 'do_dummy_2D_data_aug': False, 'pool_op_kernel_sizes': [[2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'conv_kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]]}}\n",
      "transpose forward [0, 1, 2]\n",
      "transpose backward [0, 1, 2]\n",
      "Traceback (most recent call last):\n",
      "  File \"/scratch/aoueslati/anaconda3/bin/nnUNet_plan_and_preprocess\", line 33, in <module>\n",
      "    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_plan_and_preprocess')())\n",
      "  File \"/scratch/aoueslati/nnUNet/nnunet/experiment_planning/nnUNet_plan_and_preprocess.py\", line 161, in main\n",
      "    exp_planner.run_preprocessing(threads)\n",
      "  File \"/scratch/aoueslati/nnUNet/nnunet/experiment_planning/alternative_experiment_planning/experiment_planner_pretrained.py\", line 41, in run_preprocessing\n",
      "    self.load_pretrained_plans()\n",
      "  File \"/scratch/aoueslati/nnUNet/nnunet/experiment_planning/alternative_experiment_planning/experiment_planner_pretrained.py\", line 31, in load_pretrained_plans\n",
      "    self.plans = load_pickle(self.pretrained_model_plans_file)\n",
      "  File \"/scratch/aoueslati/anaconda3/lib/python3.9/site-packages/batchgenerators/utilities/file_and_folder_operations.py\", line 57, in load_pickle\n",
      "    with open(file, mode) as f:\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'nnUNetPlansv2.1_plans_3D.pkl'\n"
     ]
    }
   ],
   "source": [
    "!nnUNet_plan_and_preprocess -t 105 -overwrite_plans nnUNetPlansv2.1_plans_3D.pkl -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier Alex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f32102",
   "metadata": {},
   "source": [
    "# A REVOIR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b4a30646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_plan_and_preprocess -t 105 -overwrite_plans pretrained_weights/new_model.model -pl3d ExperimentPlanner3D_v21_Pretrained -overwrite_plans_identifier pretrained_weights/new_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3582c2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_train 3d_fullres nnUNetTrainerV2 Task105_DHCP_RIB_MASKED 0 -w pretrained_weights/new_model.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa15d4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sbatch finetun1.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83c54c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -m 3d_fullres -t 105 -tr nnUNetTrainerV2  -val validation_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac6c2e88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!nano nnunet-7734648_3d_full_res.out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f1db8264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae90d655",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Image\n",
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "26729091",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_1/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a247e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNET_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV2__nnUNetPlansv2.1/fold_2/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15eb8618",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_0/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33e3b383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_1/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80334517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_3/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6bbf1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image('/scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_trained_models/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1/fold_4/progress.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ddd4f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#C-t 105 -overwrite_plans ExperimentPlanner3D_v21_Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "331d2db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_train 3d_fullres nnUNetTrainerV3 Task105_DHCP_RIB_MASKED 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21b59425",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_determine_postprocessing -t 105 -m 3d_fullres -pl nnUNetTrainerV3__nnUNetPlansv2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "61376ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!nnUNet_predict -i /scratch/aoueslati/predict -o /scratch/aoueslati/scratch/aoueslati/nnUNet_folder/nnUNet_Results_Folder/nnUNet/3d_fullres/Task105_DHCP_RIB_MASKED/nnUNetTrainerV3__nnUNetPlansv2.1 -f 0 -t Task105_DHCP_RIB_MASKED -tr nnUNetTrainerV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d9fb9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
